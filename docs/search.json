[
  {
    "objectID": "eng pde.html",
    "href": "eng pde.html",
    "title": "A Kun’s PDE Lecture",
    "section": "",
    "text": "菠萝和叶子"
  },
  {
    "objectID": "eng pde.html#what-is-a-number",
    "href": "eng pde.html#what-is-a-number",
    "title": "A Kun’s PDE Lecture",
    "section": "what is a number",
    "text": "what is a number\n\nQ, rational number q/p (ratio)\n\n有理数用直尺画，根号用圆规–算术平均大于几何平均\n什么是理性\n古巴比伦用宗教解释不理解的事情\n古希腊人（大自然是可理解的）带给现代人最珍贵的礼物就是理性\n爱因斯坦：大自然最不可理解的地方是大自然竟然是可理解的\n古希腊的传人\n理性的工具是数学，希腊人对数学的重视\n科技（建筑）和科学（要有主张和实验）\n\\(\\mathbb R\\)\nE.Steim\n分离变数法–傅立叶级数—分析\n微积分\n\n傅立叶 analysis\ncomplex analysis\nreal analysis\nfunctional analysis"
  },
  {
    "objectID": "eng pde.html#geometry",
    "href": "eng pde.html#geometry",
    "title": "A Kun’s PDE Lecture",
    "section": "geometry",
    "text": "geometry\nthe most important thing in geometry is about measure."
  },
  {
    "objectID": "eng pde.html#algebra",
    "href": "eng pde.html#algebra",
    "title": "A Kun’s PDE Lecture",
    "section": "algebra",
    "text": "algebra\nsimplize authority独断权威"
  },
  {
    "objectID": "eng pde.html#analysis",
    "href": "eng pde.html#analysis",
    "title": "A Kun’s PDE Lecture",
    "section": "analysis",
    "text": "analysis\ndemocracy\nNewton\nanatomy\nf(x)约等于 \\(\\Sigma a_nx^n\\)—-Talor series\nbe patient to learn analysis"
  },
  {
    "objectID": "eng pde.html#reformation",
    "href": "eng pde.html#reformation",
    "title": "A Kun’s PDE Lecture",
    "section": "Reformation",
    "text": "Reformation"
  },
  {
    "objectID": "eng pde.html#renaissance",
    "href": "eng pde.html#renaissance",
    "title": "A Kun’s PDE Lecture",
    "section": "Renaissance",
    "text": "Renaissance"
  },
  {
    "objectID": "eng pde.html#enlightenment",
    "href": "eng pde.html#enlightenment",
    "title": "A Kun’s PDE Lecture",
    "section": "Enlightenment",
    "text": "Enlightenment"
  },
  {
    "objectID": "eng pde.html#industrial-revolution",
    "href": "eng pde.html#industrial-revolution",
    "title": "A Kun’s PDE Lecture",
    "section": "Industrial Revolution",
    "text": "Industrial Revolution\nNo dynasty lasts over 300 years, except Song dynasty which lasted over 300 years, with scholars serving as prime ministers. Su Shi snored."
  },
  {
    "objectID": "eng pde.html#wave-equation",
    "href": "eng pde.html#wave-equation",
    "title": "A Kun’s PDE Lecture",
    "section": "Wave Equation",
    "text": "Wave Equation\nVibration of a string.\nTaylor, d’Alembert, Daniel Bernoulli, Jacob Bernoulli (Euler), Jacob Bernoulli (distribution).\n\\[\n\\frac{d^2x}{dt^2}\n\\]\nThe truths of this world have all been discovered by Newton.\n\\[\nu(x,t) \\text{: amplitude, } [u] = L\n\\]\n$$ [p] = M/L\n$$\n\\[\np(x,t) \\text{: density (1-dimensional)}\n\\]\n[T] = [ma] = [m][a] = ML/t^2\n\\(T=T_1=T_2\\) tension\n(0-L)\nF = Tsin() - Tsin\nm = \\(\\rho\\) x\n2nd law: \\(\\rho\\) x"
  },
  {
    "objectID": "eng pde.html#linear-transformation",
    "href": "eng pde.html#linear-transformation",
    "title": "A Kun’s PDE Lecture",
    "section": "linear transformation",
    "text": "linear transformation\nKeep the parallelogram diagonal 保持平行四边形的对角线 x+y\nkeep a straight line 保持直线—a\n向量空间 vector space\n如果是从二维映射到三维怎么办。2dim—3dim？\n代数结构\n保留加法 keep the addition\nhomomorphism\nmorphism–形象"
  },
  {
    "objectID": "eng pde.html#da..-bernulli-separation-of-variables",
    "href": "eng pde.html#da..-bernulli-separation-of-variables",
    "title": "A Kun’s PDE Lecture",
    "section": "Da.. Bernulli Separation of Variables",
    "text": "Da.. Bernulli Separation of Variables\n\\(u(x,\\theta)=\\phi(x)T(t)\\). (Gassian integral formula derivation also use this method)\n(A continuous function can be approximated by a polynomial, which is a super polynomial)\n(the defination of “density”)\n(Seperation variable: God to God, Caesar to Caesar—-x to x, t to t)\n分离变数\n\\[\n\\frac{T^{''}(t)}{C^2 T(t)} = -\\frac{\\phi^{''}(x)}{\\phi(x)}\n\\]\n\\[\n\\begin{aligned}\n&\\text{PDE:} \\quad \\text{分离变量法,separete variables} \\rightarrow \\text{ODE} \\\\\n&\\phi'' + \\lambda \\phi = 0 \\\\\n&T'' + \\lambda c^2 T = 0 \\\\\n&\\text{(B.C.) 边界条件：} \\\\\n&u(0,t) = \\phi(0) T(t) = 0 \\quad \\Rightarrow \\quad \\phi(0) = 0 \\quad \\text{(trivial 非平凡解,boring)} \\\\\n&u(L,t) = \\phi(L) T(t) = 0 \\quad \\Rightarrow \\quad \\phi(L) = 0\n\\end{aligned}\n\\]\n\\[\n\\lambda &lt; 0 \\quad , \\quad \\phi = e^{mx} \\quad \\text{(不可能，从0到0。0--0， impossible)}\n\\]\n\\[\n\\lambda = 0 \\quad , \\quad \\phi = Ax + B \\quad \\text{直线运动， straight move}\n\\]\n\\[\n\\lambda &gt; 0 \\quad , \\quad \\phi = c_1 \\cos(\\sqrt{\\lambda} x) + c_2 \\sin(\\sqrt{\\lambda} x)\n\\] ### 解的推导\n考虑方程： \\[\n\\phi'' + \\lambda \\phi = 0\n\\] 其中 () 是一个常数，解的形式取决于 () 的值。\n\n1. 当 (&lt; 0)\n当 (&lt; 0) 时，我们令 (= -^2) ，于是方程变为： \\[\n\\phi'' - \\mu^2 \\phi = 0\n\\] 其通解为： \\[\n\\phi(x) = A e^{\\mu x} + B e^{-\\mu x}\n\\] 这种解形式表示指数发散或衰减，通常是不稳定解。\n\n\n2. 当 (= 0)\n当 (= 0) 时，方程变为： \\[\n\\phi'' = 0\n\\] 这是一个线性方程，其通解为： \\[\n\\phi(x) = A x + B\n\\] 这表示直线运动。\n\n\n3. 当 (&gt; 0)\n当 (&gt; 0) 时，我们令 (= ^2) ，方程变为： \\[\n\\phi'' + \\mu^2 \\phi = 0\n\\] 其解为： \\[\n\\phi(x) = A \\cos(\\mu x) + B \\sin(\\mu x) ---wave\n\\] 这种解表示周期性波动。\n\n推导\n对于形如 ( \\(\\phi'' + \\mu^2 \\phi = 0\\) ) 的常微分方程，我们可以猜测它的解是指数形式，即：\n\\[\n\\phi(x) = e^{rx}\n\\]\n这里 ( r ) 是需要确定的参数。\n\n\n\n代入微分方程：\n将 ( (x) = e^{rx} ) 代入原方程，得到：\n\\[\nr^2 e^{rx} + \\mu^2 e^{rx} = 0\n\\]\n由于 ( e^{rx} )，可以消掉这个项，剩下的是特征方程：\n\\[\nr^2 + \\mu^2 = 0\n\\] 这个特征方程的解为：\n\\[\nr = \\pm i \\mu\n\\]\n这是一个虚数解。\n当特征根为纯虚数时，方程的通解可以写成正弦和余弦的组合形式，根据欧拉公式 ( e^{ix} = (x) + i (x) )，我们得到通解为：\n\\[\n\\phi(x) = A \\cos(\\mu x) + B \\sin(\\mu x)\n\\]\n其中，( A ) 和 ( B ) 是待定常数，它们可以通过边界条件或初始条件来确定。\ncharacteristic\n\\[\n\\phi(x) = C_1 \\cos(\\sqrt{\\lambda}x) + C_2 \\sin(\\sqrt{\\lambda}x)\n\\]\n边界条件： \\[\n\\phi(0) = 0 \\Rightarrow C_1 = 0\n\\]\n\\[\n\\phi(L) = C_2 \\sin(\\sqrt{\\lambda}L) = 0\n\\]\n因此， \\[\n\\sqrt{\\lambda_n}L = n\\pi \\quad (n = 1, 2, 3, \\dots)\n\\]\n得到本征值： \\[\n\\lambda_n = \\left( \\frac{n\\pi}{L} \\right)^2, \\quad n = 1, 2, 3, \\dots\n\\]\n对应的本征函数为： \\[\n\\phi_n(x) = \\sin \\left( \\frac{n\\pi x}{L} \\right)\n\\] Sturm-Liouville Problem:\n\\[\n\\lambda_n = \\left( \\frac{n\\pi}{L} \\right)^2, \\quad n = 1, 2, 3, \\dots\n\\]\n因此，特征函数为： \\[\n\\phi_n(x) = \\sin \\left( \\frac{n\\pi x}{L} \\right)\n\\] \\[\nT_n(t) = C_1 \\cos \\left( \\frac{n\\pi c t}{L} \\right) + C_2 \\sin \\left( \\frac{n\\pi c t}{L} \\right)\n\\]\n\\[\nu_n(x,t) = T_n(t) \\phi_n(x)\n\\]\n代入展开： \\[\nu(x,t) = \\sum_{n=1}^{\\infty} C_n \\sin \\left( \\frac{n\\pi x}{L} \\right) \\left[ C_1 \\cos \\left( \\frac{n\\pi c t}{L} \\right) + C_2 \\sin \\left( \\frac{n\\pi c t}{L} \\right) \\right]\n\\]"
  },
  {
    "objectID": "eng pde.html#law-of-large-number",
    "href": "eng pde.html#law-of-large-number",
    "title": "A Kun’s PDE Lecture",
    "section": "law of large number",
    "text": "law of large number\neg. The reason the casino makes money is because even though the people who go there have a little more than a half chance of winning, the casino has more money than you, and if you stay long enough, you will win, so don’t go to the casino, because you can’t go deeper than the casino"
  },
  {
    "objectID": "eng pde.html#does-math-have-elements",
    "href": "eng pde.html#does-math-have-elements",
    "title": "A Kun’s PDE Lecture",
    "section": "Does math have elements?",
    "text": "Does math have elements?\n             ---Paul Halmos\n             Geometric Series\n\n1-ab and 1-ba —- invertible\nI-AB invertible\n— I-BA invertible (hint: \\(I+B(I-AB)^{-1}A\\))\ndo not 杀鸡用牛刀—-\nprove the harmonic series is divergent:\nidea: geometric series:\n1+1/2+(1/3+1/4)+….\n1+(1/2+1/3)+(1/4+..+1/9)+(1/10+…+1/27)+…\\(\\geq\\) 1+(1/3)\nwhich is relevant to fuliyejishu\n学数学不要兵来将挡水来土掩，要有一个整套的思想，不要背书 idea: geometric series\n(1-ba){-1}=1/1-ba=1+ba+baba+..=1+b(1+ab+abab+..)a=1+b(1-ab){-1}a\n(1-ba)[1+b(1-ab)^{-1}a]\n1+b(1-ab){-1}a-ba-bab(1-ab){-1}a=(commutive law)=1-ba+b(1-ab){-1}a-bab(1-ab){-1}a=1-ba+b(1-ab)(1-ab)^{-1}a\n=1-ba+b1a\n=1-ba+ba\n=1 —-so do not recite boring things, remember based on understanding.\nDo not read Gassian, read Oral\nfirstly, for matrix, AB \\(\\noequal\\) BA—-f(g) is not equal to g(f)\n学学问要有感觉\nchat with different famous … 西方的没落–fu springer\nliangzilixue hysenber—max born\nthe true meaning of matrix is the linear transformation(fun f)"
  },
  {
    "objectID": "eng pde.html#p-series",
    "href": "eng pde.html#p-series",
    "title": "A Kun’s PDE Lecture",
    "section": "p-series",
    "text": "p-series\nIntegral test with dimensional analysis to know p&gt;1 for convergence\n\\(\\sum_{n=1}^{\\infty} \\frac{1}{n^p}  \\approx  \\int_1^\\infty 1/x^p \\, dx\\approx 1/[x]^p*[x]=[x]^{1-p} ([x]--&gt;\\infty)---&gt;1-p\\leq 0\\)\nagain, geometric series,\n1/12+(1/22+1/32)+(1/42+..)\n\\(\\leq 1+(1/2^2+1/2^2)+\\)\n= 1+2/2^2 +4/42+8/82z=…=2\n\nEuler\nEuler idea: Viete fumula\nrelation of root and coefficient\n\\(\\sum_{n=1}^{\\infty} \\frac{1}{n^p}=\\pi^2/6\\)\n(x-a)(x-b)=x^2-(a+b)x+ab\n(1-x/a)(1-x/b)=1-(1/a+1/b)x+1/ab*x^2\n(1-x)(1+x)\n(1-x)(1+x)(1-x/2)(1+x/2)\n(1-x)(1+x)(1-x/2)(1+x/2)…(1-x/n)(1+x/n)+…\n=1-(1/12+1/22+…+1/n2)x2+…\nQ: find a function whose roots are +-1, +-2, +-3,….\nso Euler changed this Q:\nrewrite:\n(1-x/)(1+x/)(1-x/2)(1+x/2)…\n= 1-(1/12+1/22+1/n2+…)1/2x^2+…\n先猜答案\nguess sinx = (1-x/)(1+x/)…(1-x/n)(1+x/n)\nbut 0 is a solution\nso change to sinx/x\nsinx/x =k…..\nk=limsinx/x=1\n1/x is 振幅\nsinx/x=1-(1/12+1/22+…+1/n2+…)x2/^2+…\n=1/x\n天才是创意\ncreate a thery of math\nand six/x = 1/x(x-x3/3!+…)=1-x3/6\nso we know"
  },
  {
    "objectID": "Mathematical Analysis 1.html",
    "href": "Mathematical Analysis 1.html",
    "title": "Analysis1",
    "section": "",
    "text": "和闭区间套定理极限思想的联系和区别？？？"
  },
  {
    "objectID": "Mathematical Analysis 1.html#if-a-is-an-infinite-subset-of-n-then-a-ni.e.-a-is-countably-infinite.",
    "href": "Mathematical Analysis 1.html#if-a-is-an-infinite-subset-of-n-then-a-ni.e.-a-is-countably-infinite.",
    "title": "Analysis1",
    "section": "If A is an infinite subset of N, then |A| = |N|,i.e. A is countably infinite.",
    "text": "If A is an infinite subset of N, then |A| = |N|,i.e. A is countably infinite.\n\n\nin fact， N could be any countable set"
  },
  {
    "objectID": "Mathematical Analysis 1.html#if-a-not-empty-set-has-upper-bound-then-it-must-have-the-unique-sup.",
    "href": "Mathematical Analysis 1.html#if-a-not-empty-set-has-upper-bound-then-it-must-have-the-unique-sup.",
    "title": "Analysis1",
    "section": "if a not empty set has upper bound, then it must have the unique sup.",
    "text": "if a not empty set has upper bound, then it must have the unique sup.\nProve: if a not empty set has upper bound, then it must have the unique sup.\n\nMethod 1: (Completeness axiom)\n\\[\n\\begin{gathered}\nX \\neq \\phi, \\quad Y=\\{y \\in \\mathbb{R} \\mid \\forall x \\in X(x \\leq y)\\} \\neq \\phi \\\\\n\\\\\n\\forall x \\in X, \\forall y \\in Y, x \\leq y \\\\\n\\\\\n\\Rightarrow \\exists c \\in \\mathbb R, \\forall x \\in X, \\forall y \\in Y, \\\\\n\\\\\nx \\leqslant c \\leqslant y(\\text { Completeness axiom) } \\\\\n\\\\\n\\Rightarrow(c \\in Y) \\wedge(\\{\\forall y \\in Y \\mid y \\geqslant c\\}) \\\\\n\\\\\n\\Rightarrow c=\\min Y\n\\end{gathered}\n\\]\nSo \\(c\\) is the only sup. (uniqueness of minimum element of a set—2 inequalities lead to the equality leading to the only one result).\n\n\nMethod 2: Cantor Nested Interval Property(limit思想).asdfaskfkasdjklsad\nWe choose a random upper bound \\(\\gamma, x \\in E(\\) the set) \\[\n[x, r]=\\left[a_1 b_1\\right] \\supset\\left[a_2, b_2\\right] \\supset \\cdots \\left[a_n, b_n\\right]\n\\] (each time we use the method of bisection to choose one side Including the point in \\(E\\) ) $$\n\\[\\begin{aligned}\n& \\text { Since }\\left[a_1, b_1\\right] \\supset\\left[a_2, b_2\\right] \\cdots, b_n-a_n=\\frac{\\gamma-x}{2^{n-1}} \\rightarrow 0, \\\\\n& \\beta \\in\\left[a_n, b_n\\right],(n=1,2, \\cdots), \\lim _{n \\rightarrow \\infty} a_n=\\lim _{n \\rightarrow \\infty} b_n=\\beta \\text {(limit thinking of the Cantor Nested Interval) } \\\\\n& \\Rightarrow \\forall c \\in E, c \\leqslant b_n \\Rightarrow c \\leqslant \\beta \\text { (E }  \\text {is never on the right of} [a_n,b_n]) \\\\\n& \\Rightarrow \\forall \\varepsilon&gt;0, \\exists d \\in E, d&gt;\\beta-\\varepsilon\\text { (each} [a_n,b_n] \\text { has points in E.(or see the attached picture to see more picisely))}\n\\end{aligned}\\]"
  },
  {
    "objectID": "Mathematical Analysis 1.html#if-a-not-empty-set-has-lower-bound-then-it-must-have-the-unique-inf.",
    "href": "Mathematical Analysis 1.html#if-a-not-empty-set-has-lower-bound-then-it-must-have-the-unique-inf.",
    "title": "Analysis1",
    "section": "If a not empty set has lower bound, then it must have the unique inf.",
    "text": "If a not empty set has lower bound, then it must have the unique inf.\n\nMethod 1: same as before.\n\n\nMethod 2: Based on before.\nSuppose We choose \\(m\\) as a lower bound of \\(E\\). \\[\n\\begin{aligned}\n& \\Rightarrow \\forall x \\in E, x \\geqslant m,-x \\leqslant-m \\text {. } \\\\\n& \\text { Let } F=\\{-x \\mid x \\in E\\} \\text {. } \\\\\n& \\Rightarrow \\beta=\\sup F \\\\\n& \\Rightarrow-x \\leqslant \\beta, x \\geqslant-\\beta \\text {. } \\\\\n& \\forall \\varepsilon&gt;0, \\exists-d \\in E,-d&gt;\\beta-\\varepsilon, \\\\\n& \\Rightarrow d&lt;-\\beta+\\varepsilon \\\\\n& \\Rightarrow-\\beta=\\inf E\n\\end{aligned}\n\\] \\[\n\\Rightarrow-\\sup (-E)=\\operatorname{inf} E \\text {. }\n\\]\n\n\nMethod 3 more generalized than Method 2’s conclusion (if c is negative then inf(cA)=csupA)\nIn fact, If \\(c&lt;0\\), then \\(\\sup (cA)=\\operatorname{cinf} A, \\inf (c A)=\\operatorname{csup} A\\). (and in particular. sup \\((-B)=-\\) inf \\(B\\) )\nSince if M=supA, \\(\\forall x\\in A,x\\leq M,cx\\geq cM\\), which indicates that cM is the lower bound of cX.\nSo, \\(cA\\) has lower bound ( \\(s\\) )if and only if \\(A\\) has upper bound(s).(inverse, also true) \\(cA\\) is not empty if and only if A is not empty.\nSo, cA has \\(\\inf (cA)\\) if and only if \\(A\\) has supA \\[\n\\begin{aligned}\n& \\forall c x \\in C A, c x \\geqslant c M \\\\\n& \\text { if } \\exists c M', \\forall c x \\in c A, c x \\geqslant c M^{\\prime}, c M^{\\prime}&gt;c M, \\\\\n& X \\leq M^{\\prime}, M^{\\prime}&lt;M(\\forall x \\in A)\n\\end{aligned}\n\\]\nContradicting to the condition that \\(M=\\sup A\\)\nSo \\(\\nexists C M^{\\prime}\\) So cM is the largest lower bound \\[\n\\begin{aligned}\n& \\text { so } c M=\\inf (c A) \\\\\n& \\text { so } c\\sup A=\\inf (c A)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "Mathematical Analysis 1.html#exercise-12s-sup",
    "href": "Mathematical Analysis 1.html#exercise-12s-sup",
    "title": "Analysis1",
    "section": "exercise: (1,2]’s sup–",
    "text": "exercise: (1,2]’s sup–\n\nMethod 1\n\n2 is an upper bound of [1,2) (obviously)\nif \\(\\exists \\varepsilon&gt;0\\), s.t \\(2-\\varepsilon\\) is also an upper bound of \\([1,2)\\) \\[\n\\begin{aligned}\n& \\because 1 \\in[1,2) \\\\\n& \\therefore2-\\varepsilon \\geqslant 1\n\\end{aligned}\n\\] choose \\(2-\\frac{\\varepsilon}{2} \\in(2-\\varepsilon, 2)\\) Then \\(2-\\frac{\\varepsilon}{2} \\in[1,2)\\) So \\(\\exists\\left(2-\\frac{\\varepsilon}{2}\\right) \\in[1,2)\\) while \\(\\left(2-\\frac{\\varepsilon}{2}\\right)&gt;(2-\\varepsilon)\\) So \\(2-\\varepsilon\\) is not an upper bound, contradicting to the suppose. So we have proved that 2 is the smallest upper bound, i.e. \\(\\sup [1,2)=2\\).\n\n\n\nMethod 2\n\n2 is an upper bound of [1,2) (obviously)\n\\(\\forall \\varepsilon&gt;0, \\exists b \\in[1,2)\\) with \\(b&gt;2-\\varepsilon\\). We can take \\(b=\\max \\left\\{2-\\frac{\\varepsilon}{2}, 1\\right\\}\\)."
  },
  {
    "objectID": "Mathematical Analysis 1.html#exercise-supcsupabsupasupb-from-professor-a-kun",
    "href": "Mathematical Analysis 1.html#exercise-supcsupabsupasupb-from-professor-a-kun",
    "title": "Analysis1",
    "section": "exercise: supC=sup(A+B)=supA+supB from Professor A Kun",
    "text": "exercise: supC=sup(A+B)=supA+supB from Professor A Kun\n\\[\n\\begin{array}{rl}\n\\text { if } A\\subset R,  B\\subset R, \\text { define: } \\\\\nC  :=A+B=\\{z \\in R: z=x+y, x \\in A, y \\in B\\} \\\\\nD  :=A-B=\\{z \\in R: z=x-y, x \\in A, y \\in B\\}\n\\end{array}\n\\] show that \\[\n\\begin{aligned}\n& \\text { (1) } \\sup C=\\sup (A+B)=\\sup A+\\sup B \\\\\n& \\text { (2) } \\sup D=\\sup (A-B)=\\sup A-\\inf B\n\\end{aligned}\n\\] (1) Proof:: Obviously,\\(C\\) has upper bounds if and only if \\(A\\) and \\(B\\) have upper bounds, and \\(C\\) is not empty. So \\(C\\) has sup C if and only if and only if \\(A\\) has sup \\(A\\) and \\(B\\) has sup \\(B\\). (Completeness axiom).\n\nprove: \\(\\sup C \\leqslant \\sin A+\\sup B\\). \\[\n\\because x+y \\leqslant \\sup A+\\sup  B\n\\] \\(\\therefore(\\operatorname{sip} A+\\sup B)\\) is an upper bound of \\(C\\) \\[\n\\therefore \\sin C \\leqslant \\sin A+\\sup B\n\\]\nProve : \\(\\sup C \\geqslant \\operatorname{supA}+\\) sup B \\[\n\\begin{aligned}\n& \\because \\forall \\varepsilon&gt;0, \\exists x \\in A, y \\in B \\text {, s.t. } \\\\\n& \\operatorname{sup} A-\\varepsilon&lt;x, \\operatorname{sup} B-\\varepsilon&lt;y . \\\\\n& \\Rightarrow \\sup A+\\sup B-2 \\varepsilon&lt;x+y \\\\\n& \\text { i.e. }(\\operatorname{sup} A+\\sup B-2 \\varepsilon)_{\\text {max }}&lt;(x+y)_{\\text {max }}\n\\end{aligned}\n\\]\n\nSince \\(x+y \\leq\\) sup c We have \\(\\sup A+\\sup B-2 \\varepsilon&lt;\\sup c, \\forall \\varepsilon&gt;0\\) \\[\n\\begin{aligned}\n& \\text { i.e. } \\operatorname{(sup} A+\\sup B-2 \\varepsilon)_{\\text {max }}&lt;\\sup C \\\\\n\\end{aligned}\n\\]\nWe. As \\(\\varepsilon \\rightarrow 0\\), We have \\(\\operatorname{sup} A+\\sup B \\leqslant \\operatorname{} \\operatorname{sup} C\\) So, we have \\(\\operatorname{Sup} C=\\operatorname{Sup} A+\\operatorname{Sup} B\\). Then, we have \\(\\sup D=\\sup (A-B)\\) \\[\n\\begin{aligned}\n& =\\sup (A+(-B)) \\\\\n& =\\sup A+\\sup (-B) \\\\\n& =\\sup A-\\inf B\n\\end{aligned}\n\\] (We have proved \\(\\sup (-B)=-\\inf B\\) before)\n\nanother example\n Let M ∈ R and A, B be two bounded, negative subsets of R,0 &lt; x, y &lt; M, ∀x ∈ A, y ∈ B\nwhen we are proving sup C = sup(AB) = sup A · sup B\nOn the other hand, from the definition of $a^*$ and $b^*, \\forall \\epsilon&gt;0$ there exist $a \\in A$ and $b \\in B$ such that\n\\[\na^*-\\epsilon&lt;a&lt;a^* \\quad \\text { and } \\quad b^*-\\epsilon&lt;b&lt;b^*\n\\]\nThen \\[\n\\left(a^*-\\epsilon\\right)\\left(b^*-\\epsilon\\right)&lt;a b \\leqslant a^* b^*\n\\] or ignoring \\(\\epsilon^2\\) term (If ε &gt; 0, then ε, 3ε, ε², ε⁵, they all represent “any number greater than zero”, and ε’ also represents any number greater than zero, so they are equivalent, that is, we can say that they are equal to ε’.) \\[\na^* b^*-(a+b) \\epsilon=a^* b^*-\\epsilon^{\\prime}&lt;a b \\leq c^*\n\\]\nThis is true for all \\(\\epsilon^{\\prime}&gt;0\\), so \\[\n\\sup A \\sup B=a^* b^* \\leq c^*=\\sup C\n\\]\nCombining the above two inequalities, we can conclude that \\(\\sup A \\sup B=\\) \\(\\sup C\\). ## an exercise about think good Archimedean number from Professor Andrew Lin(A Kun)\n\nConsider the set \\[\nA=\\left\\{\\left.(-1)^n\\left(1-\\frac{1}{n}\\right) \\right\\rvert\\, n \\in \\mathbb{Z}^{+}\\right\\} .\n\\]\n\n\nShow that 1 is an upper bound for \\(A\\).\nShow that if \\(d\\) is an upper bound for \\(A\\), then \\(d \\geq 1\\).\nUse (a) and (b) to show that \\(\\sup A=1\\). [Solution]:\nWe will show that for any \\(x \\in A, x \\leq 1\\). Since \\(x \\in A\\), then \\(x=(-1)^n(1-\\) \\(1 / n\\) ) for some \\(n \\in \\mathbb{Z}^{+}\\). Since \\(\\frac{1}{n}&gt;0\\), then \\(1-\\frac{1}{n}&lt;1\\). We argue our desired inequality in two cases. If \\(n\\) is even, then \\(x=(-1)^n(1-1 / n)=1-1 / n&lt;1\\). If \\(n\\) is odd, then \\(x=(-1)^n(1-1 / n)=-1+1 / n&lt;0&lt;1\\). In either case, \\(x \\leq 1\\) (in fact, \\(x&lt;1\\) ) and 1 is an upper bound for \\(A\\).\nLet \\(d\\) be an upper bound for \\(A\\). Thus, \\((-1)^n(1-1 / n) \\leq d\\) for all \\(n \\in \\mathbb{Z}^{+}\\). Assume, to the contrary that \\(d&lt;1\\). Thus, \\(1-d&gt;0\\). By the Archimedean Property, there exists an \\(n \\in \\mathbb{Z}^{+}\\)such that \\(1&lt;(1-d) n\\). Since \\(n&gt;0\\), we can rewrite this as \\(\\frac{1}{n}&lt;1-d\\), which is equivalent to \\(d&lt;1-\\frac{1}{n}\\). If \\(n\\) is even, then \\((-1)^n=1\\) and we have that \\[\nd&lt;(-1)^n\\left(1-\\frac{1}{n}\\right) \\in A\n\\] contradicting the fact that \\(d\\) is an upper bound. If \\(n\\) is odd, then consider instead \\(n+1\\), which is even. Then, \\((-1)^{n+1}=1\\) and \\[\nd&lt;1-\\frac{1}{n}&lt;(-1)^{n+1}\\left(1-\\frac{1}{n+1}\\right) \\in A\n\\]\n\nThis again contradicts that \\(d\\) is an upper bound for \\(A\\). Either way, we reach a contradiction and therefore conclude that \\(d \\geq 1\\).\n\nobviously\n\nlower bound + inequaility —smallest upper bound—sup"
  },
  {
    "objectID": "Mathematical Analysis 1.html#another-exercise-about-another-episilon-from-professor-a-kun",
    "href": "Mathematical Analysis 1.html#another-exercise-about-another-episilon-from-professor-a-kun",
    "title": "Analysis1",
    "section": "another exercise about another episilon from Professor A Kun",
    "text": "another exercise about another episilon from Professor A Kun\n\nFind the least upper bound for the following set and \\[\nA=\\left\\{\\frac{1}{2}, \\frac{2}{3}, \\frac{3}{4}, \\cdots, \\frac{n}{n+1}, \\cdots\\right\\}\n\\] [Solution]: We note that every element of \\(A\\) is less than 1 since \\[\n\\frac{n}{n+1}&lt;1, \\quad n=1,2,3, \\cdots\n\\]\n\nWe claim that the least upper bound is \\(1, \\sup A=1\\). Assume that 1 is not the least upper bound. Then there is an \\(\\epsilon&gt;0\\) such that \\(1-\\epsilon\\) is also an upper bound. However, we claim that there is a natural number \\(n\\) such that \\[\n1-\\epsilon&lt;\\frac{n}{n+1}\n\\]\nThis inequality is equivalent to the following sequence of inequalities \\[\n1-\\frac{n}{n+1}&lt;\\epsilon \\quad \\Longleftrightarrow \\quad \\frac{1}{\\epsilon}-1&lt;n\n\\]\nReversing the above sequence of inequalities shows that if \\(n&gt;\\frac{1}{\\epsilon}-1\\), then \\(1-\\epsilon&lt;\\frac{n}{n+1}\\) showing that \\(1-\\epsilon\\) is not an upper bound for \\(A\\).\n(if n &gt; 1/ \\(\\epsilon\\)-1, \\(\\nexists \\epsilon\\) s.t. 1-\\(\\epsilon\\) is an upper bound, contradicting to our suppose)\nThis verifies our answer."
  },
  {
    "objectID": "Mathematical Analysis 1.html#prove-cantor-nested-interval-property",
    "href": "Mathematical Analysis 1.html#prove-cantor-nested-interval-property",
    "title": "Analysis1",
    "section": "Prove Cantor Nested Interval Property",
    "text": "Prove Cantor Nested Interval Property\nProve:\n\n\\(\\exists c \\in\\) all closed internals\n\ni.e. if the non-empty closed intervals \\(I_1 \\supset I_2 \\supset I_3 \\cdots, \\exists c \\in R\\), s.t. \\(c\\in I_i, \\forall i \\in \\mathbb{N}\\), \\(c \\in\\) \\(\\bigcap_{i=1}^{\\infty} I_i\\)\n\nIf the limit of the lengths of these intervals are 0 then the point is unique\n\ni.e. if\\(\\left|I_n\\right| \\rightarrow 0\\), c is unique\n\n\n\\[\n\\forall \\varepsilon&gt;0, \\exists I_n(|I_n| &lt; \\varepsilon) \\Rightarrow c \\text { ! }\n\\]\nProof:\n\nproof of 1\n\n\\(I_1=[a_1, b_1]\\)\nclaim \\(\\forall I_n=[a_n, b_n], I_m=[a_m, b_m]\\) i.e. \\(a_n \\leq b_m\\)\n(if \\(a_n&gt;b_m\\), then \\(a_m \\leq b_m&lt;a_n&lt;b_n\\), which means they are separate internals without any intersection.) \\[\n\\begin{aligned}\n&\\text { Let } X=\\left\\{a_n\\right\\} (\\text { left endpoint set) } \\\\\n&\\text { Let } Y=\\left\\{b_m\\right\\}(\\text { right endpoint set) } \\\\\n& \\forall a_n \\in X, \\forall b_m \\in Y, a_n \\leq c\\leq b_m\n\\end{aligned}\n\\] \\(\\Rightarrow \\exists c \\in \\mathbb{R}\\), s.t., \\(\\forall a_n \\in X\\) \\(\\forall b_m \\in Y,a_n\\leqslant b_m\\).(completeness axiom) We then let \\(m=n \\Rightarrow c \\in I_n\\)\n\nproof of 2\n\nBased on “Any implication is equivalent to its contrapositive”\n\\[\n\\begin{aligned}\n& \\text { if } \\exists c_1&lt;c_2, \\text { s.t. } c_1, c_2 \\in I_n, \\\\\n& \\forall n \\in \\mathbb{R}, a_n \\leqslant c_1&lt;c_2 \\leqslant b_n, \\\\\n& \\Rightarrow\\left|I_n\\right|=b_n-a_n \\geqslant c_2-c_1\n\\end{aligned}\n\\]\nWe then choose \\(\\varepsilon=\\frac{c_2-c_1}{2}&gt;0\\)\nthen there exists no \\(I_n\\) s.t. \\(\\left|I_n\\right|&lt;\\varepsilon\\), since\n\\(|I_n|\\geqslant c_2-c_1 \\geqslant \\frac{c_2-c_1}{2}\\)\nSo if \\(\\exists I_n s. t .\\left|I_n\\right|&lt;\\varepsilon\\), \\(c!\\)"
  },
  {
    "objectID": "Mathematical Analysis 1.html#prove-finite-covering-lemma",
    "href": "Mathematical Analysis 1.html#prove-finite-covering-lemma",
    "title": "Analysis1",
    "section": "prove finite covering lemma",
    "text": "prove finite covering lemma\nProve：Finite Covering Lemma \\[\n\\begin{gathered}\n\\text { Def: } S:=\\{X\\}, \\text { ( } x \\text { is a set) } \\\\\nY \\subset \\bigcup_{X \\in S} X\n\\end{gathered}\n\\]\nWe say. \\(S\\) is a cover of \\(Y\\). \\[\n\\text { i.e. } \\forall y \\in Y, \\exists X \\in S,(y \\in X)\n\\]\nFinite Covering Lemma:\nIf \\(I:[a, b]\\), \\[\nI \\subset \\bigcup_{n \\in I} U_n, U_n=\\left(\\alpha_n, \\beta_n\\right)\n\\] \\(\\exists U_1, \\cdots U_k\\), s.t., \\(I\\subset \\bigcup_{i=1}^k U_i\\)\n（Summray of Finite Covering Lemma: A closed internal can be covered by finite number of open internals）\nproof:\nsuppose \\(I=[a, b]\\) could not be coverd by finite number open intervals:\nThen we use the method of bisection to separate I,s.t.\n\\[\n\\begin{aligned}\n& I=I_1 \\supset I_2 \\supset I_3 \\cdots I_n \\supset \\cdots \\text { ( all In can not be covered } \\\\\n& \\left|I_n\\right|=\\frac{b-a}{2^n} \\rightarrow 0 \\\\\n& \\text { Gover) } \\\\\n& \\Rightarrow \\exists: C \\in \\bigcap_{i=1}^{\\infty} I_i \\text { (Cantor Nested Interral Property) } \\\\\n& c_i\\in[a_i,b_i]\\\\\n& \\Rightarrow C\\in I\\subset \\bigcup U_i\\text {(based on the given condition of the proof problem)}\\\\\n& \\Rightarrow \\exists U=[\\alpha,\\beta],s.t.c\\in U，let ：\\varepsilon =min[c-\\alpha,\\beta-c]\\\\\n& \\Rightarrow I_n\\subset U\n\\end{aligned}\n\\]\n\nwhich indicates that at least this \\(I_n\\) is covered by U, contradicting to the suppose.\nso the finite covering lemma is true."
  },
  {
    "objectID": "Mathematical Analysis 1.html#statement",
    "href": "Mathematical Analysis 1.html#statement",
    "title": "Analysis1",
    "section": "statement",
    "text": "statement\np\n\n—An assertion that is either true or false but not both\ne.g.\n\nNegation of a statement p is a statement which means the opposite of P\n~p—-read “not p”\n\n\nQuantifiers\nall, every, each,no(none)—universal quantifiers\nsome,there exists, there is at least on, etc.—existential quantifiers\nP: some a’s are b’s\n~P: all a’s are not b’s/ no a’s are b’s\nP: some a are not b\n~p: all a are b\n\n\nTruth table: give the truth values of related statements in all possible cases\n(relevant to boolean in computer science)\n# Example of boolean logic in a program\nis_raining = True\nhas_umbrella = False\n\nif is_raining and not has_umbrella: # which is the only situation that implication fails\n    print(\"You need an umbrella!\")\nelse:\n    print(\"You're good to go!\")\ncompound statement: combining several statements via logical operations\nConjunction: p^q. p and q\nDisjunction: p v q–p or q\none of them is true, p v q is true, so we only need to decide if oe of them is true, if it is, the p v q is true\np V (~p) is always true\na statement that is always true is called a tautology"
  },
  {
    "objectID": "Mathematical Analysis 1.html#p101.4",
    "href": "Mathematical Analysis 1.html#p101.4",
    "title": "Analysis1",
    "section": "P10,1.4",
    "text": "P10,1.4\nEquivalence of statements: Two statements are logically equivalent, if they have the same truth values in all possible situations.\n\\(A\\equiv B\\)\n‘abstract non-sense’\nThem(De Morgan’s laws)\nA,B\n\\(\\sim (A \\land B) \\equiv (\\sim A) \\lor (\\sim B)\\)\n\\(\\sim (A \\lor B) \\equiv (\\sim A) \\land (\\sim B)\\)\ndraw truth table to look at values\n交的话（and），都T才T；并的话（or），1T则T\nConditional:\nIf p(hypothesis/assumption/condition), then q(conclusion/consequence/result).\nread: p implies q/assume p, then q.\nkey point: the implication is False when the rule is broken\n\\[\n\\begin{array}{|c|c|c|}\n\\hline\nA & B & A \\rightarrow B \\\\\n\\hline\nT & T & T \\\\\nT & F & F \\\\\nF & T & T \\\\\nF & F & T \\\\\n\\hline\n\\end{array}\n\\] Def: p, q,p–&gt;q\n1)Converse: q—&gt;p,i.e. if q, then p\n2)Contrapositive: (q)–&gt;(p), i.e. if not q, then not p\nProp: (p–&gt;q)\\(\\equiv\\) ((q)–&gt;(p))(a statement and its contrapositive are logically equivalent) \\[\n\\begin{array}{|c|c|c|c|c|c|c|}\n\\hline\np & q & \\sim p & \\sim q & p \\rightarrow q & \\sim q \\rightarrow \\sim p & (p \\rightarrow q) \\equiv (\\sim q \\rightarrow \\sim p) \\\\\n\\hline\nT & T & F & F & T & T & T \\\\\nT & F & F & T & F & F & T \\\\\nF & T & T & F & T & T & T \\\\\nF & F & T & T & T & T & T \\\\\n\\hline\n\\end{array}\n\\]\n(always remember: implication fails only when the rule brokens instead of……(others))\nProof by contradiction: we want to prove p—&gt;q, we prove (q)—-&gt;(p) instead\nproof: Assume ~q, if , then if , then … –&gt; ~p, which is contradict to the original assumption p\n   Hence the assumption ~q is false, i.e. q is true.#\n   \ne.g.: n is a natural number. Prove that if n^2 is divisible by 2(p), then n is divisible by 2(q).\nProof: Assume that n is not divisible by 2(~q),—&gt; n is odd(defination), i.e. n =2k+1,k\\(\\in Z\\)\n—&gt; n^2 =(2k+1)^2(multiplicaiton)=2()+1, which is odd\n—&gt; n^2 is not divisible by 2(~p),\nThus the aassumption that n is not divisible by 2 is false so n is divisible by 2.#\nbiconditional: p,q,\n(p–&gt;q)\\(\\land\\)(q—&gt;p)—p &lt;–&gt; q—-reads‘p if and only if q’.\nstatement converse\n\\[\n\\begin{array}{|c|c|c|c|c|}\n\\hline\np & q & p \\rightarrow q & q \\rightarrow p & p \\leftrightarrow q \\\\\n\\hline\nT & T & T & T & T \\\\\nT & F & F & T & F \\\\\nF & T & T & F & F \\\\\nF & F & T & T & T \\\\\n\\hline\n\\end{array}\n\\]\nThem.: the only case p&lt;–&gt;q is true is then both p and q ture or false"
  },
  {
    "objectID": "Mathematical Analysis 1.html#proposition",
    "href": "Mathematical Analysis 1.html#proposition",
    "title": "Analysis1",
    "section": "proposition",
    "text": "proposition\n$x,yQ $, x is less than y, \\(\\exists z\\in Q\\) s.t. x&lt;z&lt;y.\nproof: \\(x,y\\in Q, x&lt;y\\),x=m/n,x=p/q,z=x+y/2\\(\\in\\)(x+x/2,y+y/2),i.e.x&lt;z&lt;y,z=pn+mq/2qn\\(\\in \\mathbb Q\\) by defination."
  },
  {
    "objectID": "Mathematical Analysis 1.html#russel-paradox",
    "href": "Mathematical Analysis 1.html#russel-paradox",
    "title": "Analysis1",
    "section": "Russel paradox",
    "text": "Russel paradox\nlet R be the set of all sets that are not a member of themself. i.e.R={S|S\\(\\notin\\)S}\nso if \\(R\\in R\\),R\\(\\notin\\) R\nif \\(R\\notin R\\), R\\(\\in R\\)\nif \\(x\\in A\\),then \\(x\\in B\\) is the subset defination of A \\(\\subseteq\\) B.\nif \\(A\\subset B\\), A is a proper subset of B. i.e. \\(A\\subset B\\) if \\(A\\subseteq B\\) and \\(\\exists x\\in B\\), s.t. \\(x\\notin\\) A\n\\(N\\subset Z \\subset Q \\subset R\\)"
  },
  {
    "objectID": "Mathematical Analysis 1.html#proposition-1",
    "href": "Mathematical Analysis 1.html#proposition-1",
    "title": "Analysis1",
    "section": "Proposition",
    "text": "Proposition\nthe empty set is a subset of any set\nproof:\nmethod1: (truth table)\nmethod2:"
  },
  {
    "objectID": "Mathematical Analysis 1.html#def",
    "href": "Mathematical Analysis 1.html#def",
    "title": "Analysis1",
    "section": "Def",
    "text": "Def\nthe complement of A is denoted by \\(A^c\\)\nthe intersection \\(A \\cap B\\)\nthe union \\(A \\cup B\\)"
  },
  {
    "objectID": "Mathematical Analysis 1.html#countability-and-bijections",
    "href": "Mathematical Analysis 1.html#countability-and-bijections",
    "title": "Analysis1",
    "section": "Countability and Bijections",
    "text": "Countability and Bijections\nCountable Set: A set is said to be countable if it is either finite or has the same size (cardinality) as the set of natural numbers \\(\\mathbb{N}\\). A set is countably infinite if there exists a bijection (a one-to-one correspondence) between that set and \\(\\mathbb{N}\\).\nUncountable Set: A set is uncountable if no such bijection exists, meaning its cardinality is strictly greater than that of \\(\\mathbb{N}\\).\nBijection: A bijection between two sets \\(A\\) and \\(B\\) is a function \\(f: A \\to B\\) that is both injective (one-to-one) and surjective (onto).\n\nThe Problem: Showing that \\(\\mathcal{P}(\\mathbb{N})\\) is Uncountable\n\nmethod 1: Consider the set \\(A = \\{ n \\in \\mathbb{N} \\mid n \\notin f(n) \\}\\), f : N → P(N).\nwe should prove it is not a bijection. so we could prove it is not surjective (P(N) is much bigger than N).\nnow we ask if f is surjective:\nIf yes, there exists \\(n_0\\in N\\) s.t. f\\((n_0)=\\)A\nnow we ask: Does \\(n_o\\in f(n_0)\\)\n\nif yes, \\(n_0\\notin A=f(n_0)\\)\nif no, \\(n_0\\in A=f(n_0)\\)\n\nso f is not surjective, which means f could not be bijective. so p(N) is uncountable.\n\neg of a bijection between 2 sets(namely 2 sets with the same size)\n\nN-&gt;Z\nn|-&gt;n/2 if n even\nn|-&gt; n+1/2 if n odd\nmethod 2:\nThe hint in the problem suggests using a classical argument known as Cantor’s diagonal argument:\nAssume there is a bijection \\(f: \\mathbb{N} \\to \\mathcal{P}(\\mathbb{N})\\): This means each natural number \\(n \\in \\mathbb{N}\\) is paired with a unique subset of \\(\\mathbb{N}\\), i.e., \\(f(n) \\in \\mathcal{P}(\\mathbb{N})\\). Consider the set \\(S = { n \\in \\mathbb{N} \\mid n \\notin f(n) }\\): This set \\(S\\) contains all natural numbers that are not elements of their corresponding subset given by the function \\(f\\). Deriving a Contradiction: \\(S\\) is a subset of \\(\\mathbb{N}\\), so by the assumption of a bijection, there must be some \\(m \\in \\mathbb{N}\\) such that \\(f(m) = S\\). Now, ask whether \\(m \\in S\\) or \\(m \\notin S\\):\nIf \\(m \\in S\\), then by the definition of \\(S\\), we must have \\(m \\notin f(m)\\), which contradicts the fact that \\(f(m) = S\\).\nIf \\(m \\notin S\\), then \\(m\\) must be an element of \\(f(m)\\), which again contradicts the definition of \\(S\\).\nSince this contradiction arises, we conclude that no such bijection \\(f: \\mathbb{N} \\to \\mathcal{P}(\\mathbb{N})\\) can exist, and therefore \\(\\mathcal{P}(\\mathbb{N})\\) is uncountable.\nThe power set \\(\\mathcal{P}(\\mathbb{N})\\) is uncountable, meaning its cardinality is greater than that of the set of natural numbers \\(\\mathbb{N}\\), even though both sets are infinite. This conclusion is a key result in set theory, demonstrating that not all infinite sets have the same “size” or cardinality.\nHowever, for the situation of including finite subsets only,\n\n\n\n\nan eg question-Logical Puzzle on Truth of Statements relavent to truth table\nConsider the following 99 statements:\n\n\\(S_1\\): “Among these 99 statements, there is at most one true statement.”\n\\(S_2\\): “Among these 99 statements, there are at most two true statements.”\n…\n\\(S_{99}\\): “Among these 99 statements, there are at most 99 true statements.”\n\nThe goal is to determine which statements among these 99 are true.\n(hint:Consider the chain of implications from statement \\(S_n\\) to \\(S_{n+1}\\). Which statement implies which? )\nsol: we fail the hypothesis of \\(S_{n+1}\\Rightarrow S_n\\)，but because\n\\[\n\\begin{array}{|c|c|c|}\n\\hline\nS_n & S_{n+1} & S_n \\Rightarrow S_{n+1} \\\\\n\\hline\nT & T & T \\\\\nT & F & F \\\\\nF & T & T \\\\\nF & F & T \\\\\n\\hline\n\\end{array}\n\\]\nThus, we conclude that the truth of \\(S_n\\) implies the truth of all subsequent statements \\(S_{n+1}\\).\n)\n\\[\nS_n \\Rightarrow S_{n+1}\n\\] so there exists an \\(S_n\\), after which are true while before which are false.\nso:There are \\(100 - n\\) true statements.\n\\[\n100 - n \\leq n \\implies n \\geq 50\n\\]\nThere are \\(n - 1\\) false statements.\n\\[\nn - 1+1\\leq 100 - n \\implies n \\leq 50\n\\] so The 50th statement \\(S_{50}\\) is true. Statements \\(S_1\\) to \\(S_{49}\\) are false, and statements \\(S_{50}\\) to \\(S_{99}\\) are true."
  },
  {
    "objectID": "Mathematical Analysis 1.html#cardinality",
    "href": "Mathematical Analysis 1.html#cardinality",
    "title": "Analysis1",
    "section": "Cardinality",
    "text": "Cardinality\n\nnumebr of elements in a finite set: Def: let A be a set, if A contains finitely many elements, then the number of elements of A is called the cardinality of A, denoted by |A|(|A|\\(\\in Z_{\\geq0}\\)\nA, B have infinitely many elements. If \\(\\exists f:A-&gt;B\\) is a bijective map, then we regard the A, B have the same “cardinality”, i.e.|A|=|B|"
  },
  {
    "objectID": "Mathematical Analysis 1.html#a-x-bcartesian-product",
    "href": "Mathematical Analysis 1.html#a-x-bcartesian-product",
    "title": "Analysis1",
    "section": "A x B–Cartesian product",
    "text": "A x B–Cartesian product\n\neg\n|A|=3, |B|=2, |A x B|=6"
  },
  {
    "objectID": "Mathematical Analysis 1.html#map",
    "href": "Mathematical Analysis 1.html#map",
    "title": "Analysis1",
    "section": "map",
    "text": "map\nQuestion from the Cardinality:\nWhat happens if A has infinitely many elements?\nDef: LEt A and B be 2 sets, A map(function)f: A–&gt;B assigns each element in A\nthere has 3 kinds of maps(see 107)\n\neg\nthe graph of f(x) in A x B is f: A–&gt; B(x \\(\\in A\\),y\\(\\in B\\))"
  },
  {
    "objectID": "Mathematical Analysis 1.html#inverse-defination",
    "href": "Mathematical Analysis 1.html#inverse-defination",
    "title": "Analysis1",
    "section": "inverse defination",
    "text": "inverse defination\nif f is a bijective map, so as \\(f^{-1}\\)."
  },
  {
    "objectID": "Mathematical Analysis 1.html#countable",
    "href": "Mathematical Analysis 1.html#countable",
    "title": "Analysis1",
    "section": "countable",
    "text": "countable\n\nA set A is called countable if A iseither a finite set of there exists a bijective map f: A to N.(Otherwise is uncountable)\n\n\neg\n\n\\(B=[x|x=2n,n\\in N\\) is countable\n\nproof: for x|–&gt;x/2 of B–&gt;N i) injective , $x_1 $ not = \\(x_2\\), f(x_1)=x/2, = f(x_2)\n   ii) surjective, $\\forall y\\in N $, $\\exists x\\in B$ s.t. ,f(2y)=x, $2y\\in B$\n   \n   so bijective\n   \n\nZ is countable (负无穷到正无穷范围内的整数)\n\nf:N–&gt;Z(n|–&gt;n/2 if even, 1-n/2 if odd)\nn|–&gt;n/2 if even makes the positive integer possible\n1-n/2 if odd makes negative integer possible\nand both of them are bijections\nso Z is countable"
  },
  {
    "objectID": "mth1113.html",
    "href": "mth1113.html",
    "title": "Intro to probability and statistics",
    "section": "",
    "text": "across the whole range, it could not be showing a certain trend or a specific shape.\npositive and negative points sperate averagely ."
  },
  {
    "objectID": "mth1113.html#residual-plost-should-have-no-pattern",
    "href": "mth1113.html#residual-plost-should-have-no-pattern",
    "title": "MTH113 Intro to probability and statistics+APH003–exploring world through data",
    "section": "Residual plost should have no pattern",
    "text": "Residual plost should have no pattern\nacross the whole range, it could not be showing a certain trend or a specific shape.\npositive and negative points sperate averagely .\n\n\n\n# 数据\nx &lt;- c(50, 55, 50, 79, 44, 37, 70, 45, 49)  # Rock surface area\ny &lt;- c(152, 48, 22, 35, 38, 171, 13, 185, 25)  # Algae colony density\n\n# (a) 计算最小二乘回归方程\nmodel &lt;- lm(y ~ x)\nsummary(model)\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-65.53 -63.91 -14.47  46.99  84.39 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  232.258     92.390   2.514   0.0402 *\nx             -2.926      1.690  -1.731   0.1271  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 63.32 on 7 degrees of freedom\nMultiple R-squared:  0.2998,    Adjusted R-squared:  0.1997 \nF-statistic: 2.997 on 1 and 7 DF,  p-value: 0.1271\n\n# 获取回归系数\nintercept &lt;- coef(model)[1]\nslope &lt;- coef(model)[2]\ncat(\"最小二乘回归方程: y =\", intercept, \"+\", slope, \"* x\\n\")\n\n最小二乘回归方程: y = 232.2575 + -2.925507 * x\n\n# (b) 计算 R^2 值并解释\nr_squared &lt;- summary(model)$r.squared\ncat(\"R^2 值:\", r_squared, \"\\n\")\n\nR^2 值: 0.2997552 \n\ncat(\"解释: R^2 表示了\", round(r_squared * 100, 2), \"% 的 y 的变异可以通过 x 来解释。\\n\")\n\n解释: R^2 表示了 29.98 % 的 y 的变异可以通过 x 来解释。\n\n# (c) 计算残差标准误差 s_e\nse &lt;- summary(model)$sigma\ncat(\"残差标准误差 s_e:\", se, \"\\n\")\n\n残差标准误差 s_e: 63.31527 \n\ncat(\"解释: s_e 表示了回归模型的平均预测误差，越小表明预测的精确度越高。\\n\")\n\n解释: s_e 表示了回归模型的平均预测误差，越小表明预测的精确度越高。\n\n# (d) 判断线性关系的方向和强度\ncorrelation &lt;- cor(x, y)\ncat(\"相关系数 r:\", correlation, \"\\n\")\n\n相关系数 r: -0.547499 \n\nif (correlation &gt; 0) {\n  direction &lt;- \"正相关\"\n} else {\n  direction &lt;- \"负相关\"\n}\n\nif (abs(correlation) &gt; 0.7) {\n  strength &lt;- \"强相关\"\n} else if (abs(correlation) &gt; 0.3) {\n  strength &lt;- \"中等相关\"\n} else {\n  strength &lt;- \"弱相关\"\n}\n\ncat(\"线性关系:\", direction, \"且为\", strength, \"\\n\")\n\n线性关系: 负相关 且为 中等相关 \n\n\n\n# 数据\nquality_rating &lt;- c(111, 113, 93, 130, 170, 87, 83, 117, 135, 109)\nsatisfaction_rating &lt;- c(832, 845, 794, 854, 836, 842, 877, 745, 797, 795)\n\n# 计算相关系数\ncorrelation_coefficient &lt;- cor(quality_rating, satisfaction_rating)\nprint(paste(\"相关系数 r:\", correlation_coefficient))\n\n[1] \"相关系数 r: -0.115403519735578\"\n\n# 绘制散点图\nplot(quality_rating, satisfaction_rating,\n     main = \"Scatterplot of Quality Rating vs. Satisfaction Rating\",\n     xlab = \"Quality Rating\",\n     ylab = \"Satisfaction Rating\",\n     pch = 19, col = \"blue\")\nabline(lm(satisfaction_rating ~ quality_rating), col = \"red\")  # 添加回归线"
  },
  {
    "objectID": "mth1113.html#intro",
    "href": "mth1113.html#intro",
    "title": "MTH113 Intro to probability and statistics+APH003–exploring world through data",
    "section": "Intro",
    "text": "Intro\nstat is a large field in math involving the collection, organization, analysis,interpretation, and presentation of data(a collection of observations on one or more variables(A characteristic whose value may change from one observation to another))\nStatistics is the scientific discipline that provides methods to help us make sense of data.\nIt is important to be able to:\n1 Extract information from tables, charts, and graphs.\n2 Follow numerical arguments.\n3 Understand the basics of how data should be gathered, summarized, and analysed to draw statistical conclusions.\nThe Data Analysis Process\n1 Understanding the nature of the research problem or goals.\n2 Deciding what to measure and how.\n3 Collecting data.\n4 Data summarization and preliminary analysis.\n5 Formal Data Analysis (Statistical Methods).\n6 Interpretation of the results."
  },
  {
    "objectID": "mth1113.html#populations-and-samples",
    "href": "mth1113.html#populations-and-samples",
    "title": "MTH113 Intro to probability and statistics+APH003–exploring world through data",
    "section": "populations and samples",
    "text": "populations and samples\npopulation: The entire collection of individuals or objects about which information is desired\nsample: A sample is a subset of the population, selected for study.\nthen select the sample\nthen we could summarize it using 2 branches of stat.— Decriptive stat.(methods for organizing and summarizing data.) or inferential stat.(generalizing from a sample(incomplete information) to the population from which the sample was selected and assessing the reliability of such generalizations.So we run the risk(An important aspect of statistics and making statistics inferences involves quantifying the chance of making an incorrect conclusions.))\n\ndescriptive stat\n\n\ninferential stat\nsample"
  },
  {
    "objectID": "mth1113.html#types-of-data",
    "href": "mth1113.html#types-of-data",
    "title": "MTH113 Intro to probability and statistics+APH003–exploring world through data",
    "section": "Types of data",
    "text": "Types of data\n\nuni data set and bivariate and multivariate\n\n\ncategorical and numerical(discrete and continuous) with plot using excel (data analysis) or rstudio plot (ggplot2)\nfor categorial data we could use a bar chart which is a graph of a frequency distribution for categorical data.\nfor a small numerical data we could use dotplot\n\ndiscrete\n\n\nlibrary(ggplot2)\n\n# creat data：Wechat number\ndiscrete_data &lt;- data.frame(value = c(30, 15, 20,30,60))\n\n# plot\nggplot(discrete_data, aes(x = value)) +\n  geom_dotplot(binwidth = 1, dotsize = 1) +\n  ggtitle(\"Dot Plot of Discrete Data (Number of Wechats)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ncontinuous\n\n\nall_athletes &lt;- c(79, 79, 86, 85, 95, 78, 89, 84, 81, 85, 89, 89, 85, 85, 81, 80, 98, 84, \n                  80, 82, 81, 70, 85, 87, 83, 86, 92, 85, 93, 94, 76, 69, 82, 80, 94, 98)\nbasketball &lt;- c(55, 36, 83, 20, 100, 62, 100, 100, 90, 91, 93, 89, 90, 80, 46, 75, 100, 71, \n                50, 62, 82, 50, 100, 83, 90, 64, 91, 67, 83, 100, 83, 100, 83, 63, 91, 95)\n\n# 设置画布的高度，以便将两个图绘制在同一页面上\nplot.new()\nplot.window(xlim = c(0, 100), ylim = c(0.5, 2.5))\n\n# 绘制 Basketball 数据的 dotplot\nstripchart(basketball, method = \"stack\", at = 2, pch = 16, col = \"orange\", \n           add = TRUE, offset = 0.5, cex = 1.2)\n\n# 绘制 All Athletes 数据的 dotplot\nstripchart(all_athletes, method = \"stack\", at = 1, pch = 16, col = \"orange\", \n           add = TRUE, offset = 0.5, cex = 1.2)\n\n# 添加 X 轴\naxis(1, at = seq(10, 100, by = 10), labels = seq(10, 100, by = 10))\n\n# 添加标签\ntext(-5, 2, \"Basketball\", xpd = TRUE, adj = 1)\ntext(-5, 1, \"All Athletes\", xpd = TRUE, adj = 1)\n\n# 添加横线\nabline(h = 1.5, col = \"black\", lwd = 2)\n\n# 添加 X 轴标签\ntitle(xlab = \"Graduation rates (%)\")\n\n\n\n\n\n\n\n\n\n# creat data--time spent in minutes\ncontinuous_data &lt;- data.frame(value = c(6, 5.25, 3.62,1,2,3.1,3.2,4,5,6,7,4,10))\n\n# dotplot\nggplot(continuous_data, aes(x = value)) +\n  geom_dotplot(binwidth = 0.1, dotsize = 1) +\n  ggtitle(\"Dot Plot of Continuous Data (Time Spent in Minutes)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\n\n# 毕业率数据\nschool &lt;- 33:68\nall_athletes &lt;- c(79, 79, 86, 85, 95, 78, 89, 84, 81, 85, 89, 89, 85, 85, 81, 80, 98, 84, \n                  80, 82, 81, 70, 85, 87, 83, 86, 92, 85, 93, 94, 76, 69, 82, 80, 94, 98)\nbasketball &lt;- c(55, 36, 83, 20, 100, 62, 100, 100, 90, 91, 93, 89, 90, 80, 46, 75, 100, 71, \n                50, 62, 82, 50, 100, 83, 90, 64, 91, 67, 83, 100, 83, 100, 83, 63, 91, 95)\n\n# 创建数据框\ndata &lt;- data.frame(school, all_athletes, basketball)\n\n# 画图\nggplot() +\n  geom_dotplot(data = data, aes(x = all_athletes, y = \"All Athletes\"), binaxis = 'x', stackdir = 'up', dotsize = 0.5) +\n  geom_dotplot(data = data, aes(x = basketball, y = \"Basketball\"), binaxis = 'x', stackdir = 'up', dotsize = 0.5, color = \"red\") +\n  xlab(\"Graduation rates (%)\") +\n  ylab(\"\") +\n  theme_minimal() +\n  ggtitle(\"Dotplot of Graduation Rates for All Athletes and Basketball Players\")\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n\nhistogram excel plot"
  },
  {
    "objectID": "mth1113.html#collect-data-sensibly",
    "href": "mth1113.html#collect-data-sensibly",
    "title": "MTH113 Intro to probability and statistics+APH003–exploring world through data",
    "section": "collect data sensibly",
    "text": "collect data sensibly"
  },
  {
    "objectID": "Calculus.html",
    "href": "Calculus.html",
    "title": "Calculus and Multivariable Calculus",
    "section": "",
    "text": "Professor. Wang Duo, a very charismatic and responsible Calculus teacher who has worked for our country in the area of math for at least 50 years (which was his target before and he has realized his dream!), always says “You should try to solve one problem many times with new methods to handle and understand knowledge better”\nFor math learning, focusing too much on exams is not so meaningful. We should experience its beauty from the bottom of our hearts. I did not reach my target in the Multivariable Calculus and the Linear Algebra models, but Dr. Bohuan Lin said:“Exams (especially written exams) require one to figure out solutions within a very short time period, and moreover, under an intense atmosphere. From my point of view, it is really not a problem if one fails to solve those difficult and nonstandard problems under such a condition. Of course, for math study (so as for the study of other things), we should not be satisfied with merely being able to solve”standard problems”, but just try to challenge and improve yourself with deep/difficult questions under a daily condition with a natural mood, since this is the common situation in which you will be working on various tasks in your future career. ”\nThere are many ways to solve problems, and all of them are interesting when multiple integrals occur.\n\n\nIt is easy\n\n\n\n\n\nuse method of sections directly\n\n\n\n\n\n\n\nsee the photo attached, which is the easiest way for computation:\n\n\n\n\n\n\nThanks to Dr.Bohuan Lin to teach me such a clever way which we do not need to draw the picture(only use conditional equations to solve it is interesting and a little difficult to handle it correctly).\nThe picture behind the method is attached to “Steinmetz(mou he fang gai)’s photo behind.png”\nWe have the set ( D ) defined as: \\[\nD \\triangleq \\left\\{(x, y, z) \\mid \\begin{cases}\nx^2 + y^2 \\leq 4 \\\\\ny^2 + z^2 \\leq 4 \\\\\nz^2 + x^2 \\leq 4\n\\end{cases} \\right\\}\n\\]\nFrom \\[x^2+ y^2 \\leq 4 , x^2 + z^2 \\leq 4 \\] we derive: if \\[\n|x| \\geq \\sqrt{2},|y| \\leq \\sqrt{2} \\quad \\text{then} \\quad |z| \\leq \\sqrt{2}\n\\] (and &lt; is the same shape)\nSimilarly:\nif \\[|z| \\geq \\sqrt{2} ,|x| \\leq \\sqrt{2} \\quad \\text{then} \\quad |y| \\leq \\sqrt{2} \\]\nAnd: if \\[\n|z| \\geq \\sqrt{2},|y| \\leq \\sqrt{2} \\quad \\text{then} \\quad |x| \\leq \\sqrt{2}\n\\] Therefore: \\[\nD = D_{\\leq \\sqrt{2}} \\cup \\bar{D}\n\\]\nWhere: \\[\nD_{\\leq \\sqrt{2}} = \\left\\{(x, y, z) \\in D \\mid |x|, |y|, |z| \\leq \\sqrt{2} \\right\\}\n\\] \\[\n\\begin{aligned}\n&= \\left\\{ (x, y, z) \\in \\mathbb{R}^3 \\mid |x|, |y|, |z| \\leq \\sqrt{2} \\right\\} \\\\\n&= [-\\sqrt{2}, \\sqrt{2}] \\times [-\\sqrt{2}, \\sqrt{2}] \\times [-\\sqrt{2}, \\sqrt{2}]\n\\end{aligned}\n\\]\nAnd: \\[\n\\bar{D} = \\left\\{(x, y, z) \\in D \\mid |x|, |y|, |z| &gt; \\sqrt{2} \\right\\}\n\\]\nThus: \\[\n\\bar{D} = \\bar{D}_{|x| &gt; \\sqrt{2}} \\cup \\bar{D}_{|y| &gt; \\sqrt{2}} \\cup \\bar{D}_{|z| &gt; \\sqrt{2}}\n\\]\n(This also implies: \\[\nD_{\\leq \\sqrt{2}} = \\left\\{(x, y, z) \\in D \\mid |x|, |y|, |z| \\leq \\sqrt{2} \\right\\}\n\\])\nWe derive: \\[\n\\bar{D} = \\left\\{ (x, y, z) \\mid |x| &gt; \\sqrt{2} \\right\\} \\cup \\left\\{ (x, y, z) \\mid |y| &gt; \\sqrt{2} \\right\\} \\cup \\left\\{ (x, y, z) \\mid |z| &gt; \\sqrt{2} \\right\\}\n\\]\nThus, combining all components, we get: \\[\nD = \\left( D_{\\leq \\sqrt{2}} \\cup \\bar{D}_{|x| &gt; \\sqrt{2}} \\cup \\bar{D}_{|y| &gt; \\sqrt{2}} \\cup \\bar{D}_{|z| &gt; \\sqrt{2}} \\right)\n\\] So we could decompose it into a cube in the center and 6 common volume. the 6 volume: 6 \\(\\int_{ \\sqrt{2}}^{2}4(4-x^2) dx\\)\nIn summary, the whole volume is \\((2 \\sqrt 2)^3 +6\\int_{ \\sqrt{2}}^{2}4(4-x^2) dx\\)\n\n\n\n\nThanks to Dr. Haoran Chen for teaching us such method.\nWe suppose z&gt;x, z&gt;y,（then *3） then we could continue decompose it into (1)z~(\\(\\sqrt 2\\),2) and (2)z~(\\(0,\\sqrt 2\\))(based on whether the square is out of the circle)\n\n\n\n\nsee the photo attached"
  },
  {
    "objectID": "Calculus.html#cylinders",
    "href": "Calculus.html#cylinders",
    "title": "Calculus and Multivariable Calculus",
    "section": "",
    "text": "It is easy\n\n\n\n\n\nuse method of sections directly\n\n\n\n\n\n\n\nsee the photo attached, which is the easiest way for computation:\n\n\n\n\n\n\nThanks to Dr.Bohuan Lin to teach me such a clever way which we do not need to draw the picture(only use conditional equations to solve it is interesting and a little difficult to handle it correctly).\nThe picture behind the method is attached to “Steinmetz(mou he fang gai)’s photo behind.png”\nWe have the set ( D ) defined as: \\[\nD \\triangleq \\left\\{(x, y, z) \\mid \\begin{cases}\nx^2 + y^2 \\leq 4 \\\\\ny^2 + z^2 \\leq 4 \\\\\nz^2 + x^2 \\leq 4\n\\end{cases} \\right\\}\n\\]\nFrom \\[x^2+ y^2 \\leq 4 , x^2 + z^2 \\leq 4 \\] we derive: if \\[\n|x| \\geq \\sqrt{2},|y| \\leq \\sqrt{2} \\quad \\text{then} \\quad |z| \\leq \\sqrt{2}\n\\] (and &lt; is the same shape)\nSimilarly:\nif \\[|z| \\geq \\sqrt{2} ,|x| \\leq \\sqrt{2} \\quad \\text{then} \\quad |y| \\leq \\sqrt{2} \\]\nAnd: if \\[\n|z| \\geq \\sqrt{2},|y| \\leq \\sqrt{2} \\quad \\text{then} \\quad |x| \\leq \\sqrt{2}\n\\] Therefore: \\[\nD = D_{\\leq \\sqrt{2}} \\cup \\bar{D}\n\\]\nWhere: \\[\nD_{\\leq \\sqrt{2}} = \\left\\{(x, y, z) \\in D \\mid |x|, |y|, |z| \\leq \\sqrt{2} \\right\\}\n\\] \\[\n\\begin{aligned}\n&= \\left\\{ (x, y, z) \\in \\mathbb{R}^3 \\mid |x|, |y|, |z| \\leq \\sqrt{2} \\right\\} \\\\\n&= [-\\sqrt{2}, \\sqrt{2}] \\times [-\\sqrt{2}, \\sqrt{2}] \\times [-\\sqrt{2}, \\sqrt{2}]\n\\end{aligned}\n\\]\nAnd: \\[\n\\bar{D} = \\left\\{(x, y, z) \\in D \\mid |x|, |y|, |z| &gt; \\sqrt{2} \\right\\}\n\\]\nThus: \\[\n\\bar{D} = \\bar{D}_{|x| &gt; \\sqrt{2}} \\cup \\bar{D}_{|y| &gt; \\sqrt{2}} \\cup \\bar{D}_{|z| &gt; \\sqrt{2}}\n\\]\n(This also implies: \\[\nD_{\\leq \\sqrt{2}} = \\left\\{(x, y, z) \\in D \\mid |x|, |y|, |z| \\leq \\sqrt{2} \\right\\}\n\\])\nWe derive: \\[\n\\bar{D} = \\left\\{ (x, y, z) \\mid |x| &gt; \\sqrt{2} \\right\\} \\cup \\left\\{ (x, y, z) \\mid |y| &gt; \\sqrt{2} \\right\\} \\cup \\left\\{ (x, y, z) \\mid |z| &gt; \\sqrt{2} \\right\\}\n\\]\nThus, combining all components, we get: \\[\nD = \\left( D_{\\leq \\sqrt{2}} \\cup \\bar{D}_{|x| &gt; \\sqrt{2}} \\cup \\bar{D}_{|y| &gt; \\sqrt{2}} \\cup \\bar{D}_{|z| &gt; \\sqrt{2}} \\right)\n\\] So we could decompose it into a cube in the center and 6 common volume. the 6 volume: 6 \\(\\int_{ \\sqrt{2}}^{2}4(4-x^2) dx\\)\nIn summary, the whole volume is \\((2 \\sqrt 2)^3 +6\\int_{ \\sqrt{2}}^{2}4(4-x^2) dx\\)\n\n\n\n\nThanks to Dr. Haoran Chen for teaching us such method.\nWe suppose z&gt;x, z&gt;y,（then *3） then we could continue decompose it into (1)z~(\\(\\sqrt 2\\),2) and (2)z~(\\(0,\\sqrt 2\\))(based on whether the square is out of the circle)\n\n\n\n\nsee the photo attached"
  },
  {
    "objectID": "Calculus.html#integral-problems-with-solution-of-alternating-integral-test",
    "href": "Calculus.html#integral-problems-with-solution-of-alternating-integral-test",
    "title": "Calculus and Multivariable Calculus",
    "section": "integral problems with solution of alternating integral test",
    "text": "integral problems with solution of alternating integral test\nquestion: does \\[\\int_{0}^{\\infty}sinx/x\\,dx\\] converge?\nIt is easy to think of these 2 famous but difficultly proved formula: \\[\\int_{-\\infty}^{\\infty}sinx/x\\,dx=\\pi\n\\] \\[\\int_{-\\infty}^{\\infty}e^{-x^2}\\,dx=\\pi\n\\] However, they are not useful, which is how charasmatic the math is! I love math!\n\\[=\\Sigma_{n=1}^{\\infty}\\int_{2(n-1)\\pi}^{2n\\pi}sinx/x\\,dx\n\\] Then we let \\(x-[2(n-1)\\pi]=y\\)(dx=dy)\nso \\[=\\Sigma_{n=1}^{\\infty}\\int_{0}^{2\\pi}siny/(y+[2(n-1)\\pi])\\,dy\\] =\\[=\\Sigma_{n=1}^{\\infty}\\int_{0}^{\\pi}siny/(y+[2(n-1)\\pi])\\,dy+\\Sigma_{n=1}^{\\infty}\\int_{\\pi}^{2\\pi}siny/(y+[2(n-1)\\pi])\\,dy\\]\nThen we let y-\\(\\pi\\)=z(dy=dz)\n\\[=\\Sigma_{n=1}^{\\infty}\\int_{0}^{\\pi}siny/(y+[2(n-1)\\pi])\\,dy+\\Sigma_{n=1}^{\\infty}\\int_{0}^{\\pi}-sinz/(z+[(2n-1)\\pi])\\,dz\\] \\[=\\Sigma_{n=1}^{\\infty}\\int_{0}^{\\pi}sinm/(m+[2(n-1)\\pi])\\,dm+\\Sigma_{n=1}^{\\infty}\\int_{0}^{\\pi}-sinm/(m+[(2n-1)\\pi])\\,dm\\]\nso if \\[a_n=\\int_{0}^{\\pi}sinm/(m+(n-1)\\pi)\\] \\[\\int_{0}^{\\infty}sinx/x\\,dx=a_1-a_2+a_3-a_4+...+a_n\\], which is an alternating series!\nCoincidently, it is decresing and \\(a_n&lt;\\int_{0}^{\\pi}1/(n-1)\\pi\\,dm=1/(n-1)\\), and \\(\\lim_{{n \\to \\infty}} \\left( \\frac{1}{n-1}  \\right) = 0\\) so \\(\\lim_{{n \\to \\infty}}a_n=0\\) So it converges(Alternating series test)."
  },
  {
    "objectID": "Calculus.html#similar-question-2",
    "href": "Calculus.html#similar-question-2",
    "title": "Calculus and Multivariable Calculus",
    "section": "similar question 2",
    "text": "similar question 2\nThanks for Dr.Chi-Kun Lin to teach me this kind of problems!\n\\[\n\\int_0^\\infty \\frac{1}{1 + x^p \\sin^2 x} \\, dx\n\\]\n\n\n\n\\[\n\\sum_{n=0}^\\infty \\int_0^{\\frac{\\pi}{2}} \\frac{1}{1 + \\left( n + \\frac{1}{2} \\right)^2 p \\sin^2 t} \\, dt = \\int_0^{\\frac{\\pi}{2}} \\frac{1}{1 + \\left( n + \\frac{1}{2} \\right)^2 p \\sin^2 t} \\, dt\n\\]\n\\[\\Sigma\\int_0^{\\frac{\\pi}{2}} \\frac{1}{1 + \\left( n\\pi/2 + t \\right)^ p \\sin^2 t} \\, dt + \\int_0^{\\frac{\\pi}{2}} \\frac{1}{1 + \\left(( n + 1 \\right)\\pi/2-t)^ p sin^2t} \\, dt\\]\nfor:\n\\[\nx_n = \\Sigma\\int_0^{\\frac{\\pi}{2}} \\frac{1}{1 + \\left( n\\pi/2 + t \\right)^ p \\sin^2 t} \\, dt + \\int_0^{\\frac{\\pi}{2}} \\frac{1}{1 + \\left(( n + 1 \\right)\\pi/2-t)^ p sin^2t} \\, dt,\n\\]\nthere has\n\\[2 \\int_0^{\\frac{\\pi}{2}} \\frac{1}{1 + \\left( (n + 1) \\frac{\\pi}{2} \\right)^ p t^2} \\, dt \\leq x_n \\leq 2 \\int_0^{\\frac{\\pi}{2}} \\frac{1}{1 + \\left( (n + 1) \\frac{\\pi}{2} \\right) ^p \\frac{4}{\\pi^2} t^2} \\, dt\\]\n\nHowever, the integrals on both sides of the inequality can be calculated separately. For example:\n\n\\[\n\\int_0^1 \\frac{1}{1 + \\left( (n + 1) \\frac{\\pi}{2} \\right)^ p t^2} \\, dt = \\frac{1}{\\sqrt{((n + 1) \\frac{\\pi}{2} )^p}} \\arctan \\left( \\sqrt{(n + 1) \\frac{\\pi}{2}}^{2p}\\pi/2 \\right) \\geq \\frac{1}{\\sqrt{(n + 1) \\frac{\\pi}{2} }^{2p}  } \\frac{\\pi}{4}\n\\]"
  },
  {
    "objectID": "Calculus.html#lagrange-multipliers",
    "href": "Calculus.html#lagrange-multipliers",
    "title": "Calculus and Multivariable Calculus",
    "section": "Lagrange Multipliers",
    "text": "Lagrange Multipliers\nThe method of Lagrange multipliers is used to solve optimization problems with constraints. It involves introducing Lagrange multipliers to incorporate constraints into the objective function, converting constrained problems into unconstrained problems. Given an objective function ( f() ) with constraints ( g_i() = 0 ), the Lagrange function is:\n[ (, ) = f() + _{i} _i g_i() ]\nwhere (_i) are the Lagrange multipliers. By setting the derivatives of () to zero, we can find the optimal solution."
  },
  {
    "objectID": "Calculus.html#relationship-between-lasso-and-lagrange-multipliers",
    "href": "Calculus.html#relationship-between-lasso-and-lagrange-multipliers",
    "title": "Calculus and Multivariable Calculus",
    "section": "Relationship Between Lasso and Lagrange Multipliers",
    "text": "Relationship Between Lasso and Lagrange Multipliers\nIn Lasso regression, the L1 norm regularization term (||_1) can be viewed as a constraint. The Lasso problem can be reformulated as a constrained optimization problem:\n[ | - |_2^2 ||_1 t ]\nwhere (t) is a non-negative constant representing the limit on the regularization strength.\n\nUsing Lagrange Multipliers for Lasso\nWe can use Lagrange multipliers to solve this constrained problem. The Lagrange function is defined as:\n[ (, ) = | - |_2^2 + (||_1 - t) ]\nwhere () is the Lagrange multiplier. The optimal solution (^*) satisfies:\n[ = -^( - ) + () = 0 ]\n[ ||_1 t ]\n[ (||_1 - t) = 0 ]"
  },
  {
    "objectID": "Calculus.html#summary",
    "href": "Calculus.html#summary",
    "title": "Calculus and Multivariable Calculus",
    "section": "Summary",
    "text": "Summary\n\nLasso Regression uses L1 regularization to achieve feature selection, and its optimization problem can be transformed into a constrained optimization problem.\nLagrange Multipliers provide a method to handle constraints in optimization problems by converting them into unconstrained problems and introducing multipliers to adjust the regularization strength.\n\nIn Lasso regression, the L1 regularization constraint can be handled using Lagrange multipliers, converting the problem into one with multipliers that adjust the strength of regularization. ### Problem\nFind extreme values of\n\\[ f(x, y) = \\cos x + \\cos y + \\cos (x + y). \\]\n\nSolution\nSince cosine is a periodic function, we can consider the region ( 0 x ), ( 0 y ) (bounded and closed region) to find the maximal and minimal values.\nFirstly, we consider the interior of the region to find stationary points:\n\\[ f_x = -\\sin x - \\sin (x + y) = 0 \\] \\[ f_y = -\\sin y - \\sin (x + y) = 0 \\]\nThis implies:\n\\[ \\sin x = \\sin y \\]\nThen, inside the region (not on boundary), we have three cases:\n\n( y = x )\n( y = - x ) for ( 0 &lt; x &lt; )\n( y = 3- x ) for ( &lt; x &lt; 2)\n\n\nCase 1\n\\[ \\sin x + \\sin (x + y) = \\sin x + 2 \\sin x \\cos x = 0 \\] \\[ \\sin x (2 \\cos x + 1) = 0 \\]\nThis implies:\n\\[ x = \\pi, y = \\pi \\] or \\[ x = \\frac{2\\pi}{3}, y = \\frac{2\\pi}{3} \\] or \\[ x = \\frac{4\\pi}{3}, y = \\frac{4\\pi}{3} \\]\nEvaluating the function at these points:\n\\[ f(\\pi, \\pi) = -1 \\] \\[ f\\left( \\frac{2\\pi}{3}, \\frac{2\\pi}{3} \\right) = -\\frac{3}{2} \\] \\[ f\\left( \\frac{4\\pi}{3}, \\frac{4\\pi}{3} \\right) = -\\frac{3}{2} \\]\n\n\nCase 2\n\\[ \\sin x + \\sin (x + y) = \\sin x + \\sin \\pi = \\sin x = 0 \\]\nThis implies:\n\\[ x = \\pi, y = 0 \\] (on boundary)\n\n\nCase 3\n\\[ \\sin x + \\sin (3\\pi - x) = \\sin x = 0 \\]\nThis implies:\n\\[ x = \\pi, y = 2\\pi \\] (also on boundary)\n\n\n\nOn the Boundary\nDue to periodic property, we consider:\n\\[ x = 0, 0 \\leq y \\leq 2\\pi \\] and \\[ y = 0, 0 \\leq x \\leq 2\\pi \\]\nEvaluating the function at these boundaries:\n\\[ f(0, y) = 1 + 2 \\cos y, \\min = -1, \\max = 3 \\] \\[ f(x, 0) = 1 + 2 \\cos x, \\min = -1, \\max = 3 \\]\nSo,\n\\[ \\max f(x, y) = 3 \\text{ at } (2n\\pi, 2k\\pi) \\text{ for any } n, k \\in \\mathbb{Z} \\] \\[ \\min f(x, y) = -\\frac{3}{2} \\text{ at } \\left( (2n+1)\\pi \\pm \\frac{\\pi}{3}, (2k+1)\\pi \\pm \\frac{\\pi}{3} \\right) \\]"
  },
  {
    "objectID": "mth107.html",
    "href": "mth107.html",
    "title": "MTH107—NOTEs",
    "section": "",
    "text": "matrix-vector multiplication\ndifferentiation/integration\nODE(mth106)\nRecurrence Relations and Statistical Models\n\n\n\n\n\nA matrix A in this space is a real matrix, which maps vectors in \\(\\mathbb{R^n}\\) to another vector in \\(\\mathbb{R^n}\\) through multiplication: \\[\nA: \\mathbb{R^n} \\to \\mathbb{R^n}\n\\] \\[\nA \\cdot v = w \\in \\mathbb{R^n}\n\\]\nreal matrix\nconcrete\n\n\n\nlinear transformation: \\[\nT: V \\to W\n\\] abstract and more general vector space over \\(\\mathbb{R^n}\\) or \\(\\mathbb{C^n}\\)\n\n\n\n\n\n\\[\na \\in A\n\\] eg. \\[\n3 \\in \\mathbb{Z}\n\\]\n\\(\\emptyset\\)\nTwo sets A and B are equal if and only if they contain the same elements: \\[\nA = B\n\\] if and only if \\[\n\\forall x \\, (x \\in A \\iff x \\in B)\n\\] \\[ A \\subseteq B\\]\nintersection: \\[ A \\cap B\\]\nunion: \\[ A\\cup B \\]\n\n\n\n\nmaps(functions)\n\\[\nf: A \\to B, \\quad a \\mapsto f(a)\n\\] composition: Given two functions \\(f: B \\to C\\) and \\(g: A \\to B\\), the composition of f and g is denoted as: \\[\n(f \\circ g)(x) = f(g(x)), \\quad \\text{for all} \\, x \\in A\n\\]\n\\[\na \\mapsto c(a \\mapsto b \\mapsto c)\n\\]\n\n\nif \\(a_1 \\neq a_2\\) then \\(f(a_1) \\neq f(a_2)\\)\nif \\(f(a_1) = f(a_2)\\), then \\(a_1=a_2\\)\n\n\n\nfor \\(f: A \\to B\\)\n\\[\n\\forall b \\in B, \\, \\exists a \\in A \\, \\text{such that} \\, f(a) = b\n\\]\n\n\n\nfor \\(f: A \\to B\\) \\[\n\\forall b \\in B, \\, \\exists! a \\in A \\, \\text{such that} \\, f(a) = b\n\\] （use \\(\\exists!\\)expresses only exist one）\nf: x–&gt;y is a bijection if and only if \\(\\exists\\)g:y—&gt;x, s.t. f(g(y))=\\(id_y\\) and g(f(x))=\\(id_x\\)\n\n\n\n\n\n\n\\(A \\subseteq B\\)\n\n\n\n\\[\n\\emptyset \\to B\n\\]\n\n\n\nif A \\(\\subseteq\\) B, we have a map: \\[\n\\iota: A \\to B\n\\]\n\\[\n\\iota(a) = a\n\\], called the inclusion of A (into B)\n\n\n\nThat is:\nif A \\(\\subseteq\\) B and \\(f:B \\to C\\), we have a map for all a \\(\\in\\) A: \\[\nf|_A: A \\to C\n\\]:\n\\[\nf|_A(a) = f(a)\n\\] called the restriction of f to A\n\\[\nf|_A = f \\circ \\iota_A\n\\] because \\[\nf \\circ \\iota_A(a)=f(\\iota_A(a))=f(a)=f|_A(a)\n\\]\nthe reason to define it:\n\ndomains differ\n\nFor example, consider a map \\(g|_B: B \\to C\\), where the function takes each element \\(x\\) and maps it to \\(x + 2\\). Let the sets be as follows:\n\n\\(A = \\mathbb{N} \\subseteq B = \\mathbb{R}\\)\n\\(C = \\mathbb{R}\\) is the codomain of the function.\n\nThe map \\(g\\) is defined as: \\[ g: B \\to C, \\quad g(x) = x + 2 \\quad \\text{for all } x \\in B \\]\nNow, consider the restriction of \\(g\\) to \\(A\\), denoted \\(g|_A: A \\to C\\), where: \\[ g|_A: A \\to C, \\quad g|_A(x) = x + 2 \\quad \\text{for all } x \\in A \\]\nAlthough both \\(g: \\mathbb{R} \\to \\mathbb{R}\\) and \\(g|_A: \\mathbb{N} \\to \\mathbb{R}\\) follow the same rule \\(x \\mapsto x + 2\\), they cannot be considered the same map because their domains differ.\n(here, A \\(\\subseteq\\) B)\n\nfocus on the specific area within the whole area\n\n\n\n\nif a and b are sets we define \\(B^A={f:A---&gt;B (map)}\\) the set of all maps from A to B\n\\[\nB^A = \\{ f: A \\to B \\}\n\\] \\(B^\\emptyset = \\{ \\emptyset \\to B \\}\\) has only 1 element even if B=\\(\\emptyset\\)\n\nThe set \\(B^{\\emptyset}\\) contains only the zero function. proof: suppose f,g \\(\\in\\) \\(B^\\emptyset = \\{f: \\emptyset \\to B \\}\\), imagine f != g, we can derive \\(\\exists x \\in \\emptyset\\) s.t. f(x) != g(x), which is absurd, so f=g\n\nsuppose the only one element is sth.:\nsth. should follow the quality of the set, which is:\nsth. + sth. = sth.\n\\(\\lambda\\)sth. =sth.\nso sth. = 0\n\n\n(Def: let A be a.set, if A containsfinitely many elements, then the number of elements of A is called the cardinality of A, denoted by |A|(|A|\\(\\in Z_{\\geq0}\\))\n|| #\n|A|: number of elements in A(set))\nif A and B are finite sets #A=n #B=m, then \\(|B^A| = m^n\\) (ok)\n\n\n\n\n\n\n\n\nMLR\n\n\nmatrix\n\n\nIn linear regression, we often work with matrix and vector representations. Given a matrix \\(X\\) (which represents the design matrix with each row corresponding to one observation and each column to a predictor), and a vector \\(Y\\) (representing the observed responses), the regression model can be written as:\n\\[\nY = X \\beta + \\epsilon\n\\]\nWhere: - \\(Y\\): The \\(n \\times 1\\) response vector, - \\(X\\): The \\(n \\times p\\) design matrix, - \\(\\beta\\): The \\(p \\times 1\\) vector of unknown coefficients, - \\(\\epsilon\\): The \\(n \\times 1\\) vector of errors or residuals.\nThe ordinary least squares (OLS) estimator for \\(\\beta\\), denoted \\(\\hat{\\beta}\\), is obtained by minimizing the residual sum of squares:\n\\[\n\\hat{\\beta} = (X^T X)^{-1} X^T Y\n\\]\n\n\n\nConsider two vectors \\(X_1\\) and \\(X_2\\). If \\(X_1^T X_2 = 0\\), we say the vectors are orthogonal, meaning they are uncorrelated in terms of inner product space. In regression, orthogonality implies no collinearity between predictors.\nOrthogonality plays an important role in simplifying matrix operations in regression. For example, if \\(X_1\\) is orthogonal to \\(X_2\\), the matrix \\(X^T X\\) will have off-diagonal elements equal to zero, simplifying the computation of the inverse.\n\n\n\nIf the matrix \\(X^T X\\) is invertible, the OLS estimator exists and is unique. One important property of the matrix \\(X^T X\\) is that it is symmetric and positive semi-definite. If \\(X\\) has full column rank (meaning that the columns of \\(X\\) are linearly independent), then \\(X^T X\\) is positive definite, and its inverse exists.\n\n\nIf \\(X^T X\\) is invertible, then:\n\\[\n(X^T X)^{-1} X^T X = I_p\n\\]\nWhere \\(I_p\\) is the identity matrix of size \\(p \\times p\\).\n\n\n\n\nThe projection matrix (or hat matrix) \\(P\\) is defined as:\n\\[\nP = X (X^T X)^{-1} X^T\n\\]\nThis matrix \\(P\\) projects the observed data vector \\(Y\\) onto the column space of \\(X\\), giving the fitted values \\(\\hat{Y}\\):\n\\[\n\\hat{Y} = P Y\n\\]\nThe residuals \\(\\hat{\\epsilon}\\), which are the differences between the observed and fitted values, are given by:\n\\[\n\\hat{\\epsilon} = Y - \\hat{Y} = (I_n - P) Y\n\\]\nWhere \\(I_n\\) is the \\(n \\times n\\) identity matrix. The projection matrix \\(P\\) has several key properties: - \\(P^2 = P\\) (idempotent), - \\(P^T = P\\) (symmetric).\n\n\n\nThe residual sum of squares (RSS) is given by:\n\\[\n\\text{RSS} = \\sum_{i=1}^{n} \\hat{\\epsilon}_i^2 = \\hat{\\epsilon}^T \\hat{\\epsilon} = (Y - X \\hat{\\beta})^T (Y - X \\hat{\\beta})\n\\]\nSubstituting \\(\\hat{\\beta} = (X^T X)^{-1} X^T Y\\), we get:\n\\[\n\\text{RSS} = Y^T (I_n - P) Y\n\\]\n\n\n\nThe variance-covariance matrix of the OLS estimator \\(\\hat{\\beta}\\) is:\n\\[\n\\text{Var}(\\hat{\\beta}) = \\sigma^2 (X^T X)^{-1}\n\\]\nWhere \\(\\sigma^2\\) is the variance of the error terms. This matrix provides information about the precision of the estimated coefficients.\n\n\n\n\nConsider a vector \\(y\\) in the vector space spanned by the columns of \\(X\\). The projection of \\(y\\) onto this space can be written as:\n\\[\n\\hat{y} = P y\n\\]\nIf \\(P\\) is the projection matrix, then the following properties hold: - \\(P^T = P\\) (symmetric), - \\(P^2 = P\\) (idempotent), - \\((I - P)\\) is also a projection matrix (projecting onto the orthogonal complement).\nThus, we can decompose any vector \\(Y\\) as:\n\\[\nY = \\hat{Y} + (Y - \\hat{Y}) = P Y + (I - P) Y\n\\]\nWhere \\(\\hat{Y}\\) is the projection onto the space spanned by \\(X\\), and \\((Y - \\hat{Y})\\) is the projection onto the orthogonal complement.\n\n\n\n\nA vector \\(\\perp\\) to a matrix \\(X\\) (i.e., orthogonal to the column space of the matrix \\(X\\)) implies that:\n\n\\[\nX^T v = 0\n\\]\nThis condition means that the vector \\(v\\) is orthogonal to every column of the matrix \\(X\\). In regression, this condition often arises when discussing residuals, which are orthogonal to the fitted values (i.e., the column space of \\(X\\)).\n\n\n\n\nIf \\(X^T v = 0\\), then \\(v \\perp X\\) (i.e., \\(v\\) is orthogonal to the column space of \\(X\\)).\nIf \\(X\\) has linearly independent columns, then \\(X^T X\\) is invertible.\nIf \\(X\\) does not have full column rank, then \\(X^T X\\) is not invertible. In this case, we cannot directly compute \\((X^T X)^{-1}\\).\n\n\n\n\nFor \\(X\\) to have full column rank, the number of columns \\(p\\) must be less than or equal to the number of observations \\(n\\):\n列空间的正交补空间只有零向量 he orthogonal complement of a column space has only zero vectors\nIf \\(X\\) has full column rank, then \\(X^T X\\) is invertible. This property is crucial for solving the normal equations in ordinary least squares (OLS) regression.\n\n\n\nGiven that \\(X^T X\\) is symmetric, the following property holds:\n\\[\n((X^T X)^{-1})^T = (X^T X)^{-1}\n\\]\nThis is a key result in linear regression, allowing us to solve for the OLS estimator of \\(\\beta\\):\n\\[\n\\hat{\\beta} = (X^T X)^{-1} X^T Y\n\\]\nThis property ensures that the normal equations have a unique solution when \\(X^T X\\) is invertible.\n\n\n\n\n\n正交性：矢量与矩阵的正交性在回归中经常用于描述残差与拟合值之间的关系。\n矩阵的性质：矩阵 \\(X^T X\\) 的可逆性取决于 \\(X\\) 的列满秩（线性无关性）。当 \\(X\\) 的列满秩时，\\(X^T X\\) 是可逆的，从而确保了线性回归模型的唯一解。\n矩阵运算：通过矩阵运算 \\((X^T X)^{-1}\\)，可以得到 OLS 回归系数的估计值 \\(\\hat{\\beta}\\)。"
  },
  {
    "objectID": "mth107.html#linearty-is-everywherelinearty-is-the-easiest-one",
    "href": "mth107.html#linearty-is-everywherelinearty-is-the-easiest-one",
    "title": "MTH107—NOTEs",
    "section": "",
    "text": "matrix-vector multiplication\ndifferentiation/integration\nODE(mth106)\nRecurrence Relations and Statistical Models"
  },
  {
    "objectID": "mth107.html#comparison",
    "href": "mth107.html#comparison",
    "title": "MTH107—NOTEs",
    "section": "",
    "text": "A matrix A in this space is a real matrix, which maps vectors in \\(\\mathbb{R^n}\\) to another vector in \\(\\mathbb{R^n}\\) through multiplication: \\[\nA: \\mathbb{R^n} \\to \\mathbb{R^n}\n\\] \\[\nA \\cdot v = w \\in \\mathbb{R^n}\n\\]\nreal matrix\nconcrete\n\n\n\nlinear transformation: \\[\nT: V \\to W\n\\] abstract and more general vector space over \\(\\mathbb{R^n}\\) or \\(\\mathbb{C^n}\\)"
  },
  {
    "objectID": "mth107.html#notations",
    "href": "mth107.html#notations",
    "title": "MTH107—NOTEs",
    "section": "",
    "text": "\\[\na \\in A\n\\] eg. \\[\n3 \\in \\mathbb{Z}\n\\]\n\\(\\emptyset\\)\nTwo sets A and B are equal if and only if they contain the same elements: \\[\nA = B\n\\] if and only if \\[\n\\forall x \\, (x \\in A \\iff x \\in B)\n\\] \\[ A \\subseteq B\\]\nintersection: \\[ A \\cap B\\]\nunion: \\[ A\\cup B \\]"
  },
  {
    "objectID": "mth107.html#maps",
    "href": "mth107.html#maps",
    "title": "MTH107—NOTEs",
    "section": "",
    "text": "maps(functions)\n\\[\nf: A \\to B, \\quad a \\mapsto f(a)\n\\] composition: Given two functions \\(f: B \\to C\\) and \\(g: A \\to B\\), the composition of f and g is denoted as: \\[\n(f \\circ g)(x) = f(g(x)), \\quad \\text{for all} \\, x \\in A\n\\]\n\\[\na \\mapsto c(a \\mapsto b \\mapsto c)\n\\]\n\n\nif \\(a_1 \\neq a_2\\) then \\(f(a_1) \\neq f(a_2)\\)\nif \\(f(a_1) = f(a_2)\\), then \\(a_1=a_2\\)\n\n\n\nfor \\(f: A \\to B\\)\n\\[\n\\forall b \\in B, \\, \\exists a \\in A \\, \\text{such that} \\, f(a) = b\n\\]\n\n\n\nfor \\(f: A \\to B\\) \\[\n\\forall b \\in B, \\, \\exists! a \\in A \\, \\text{such that} \\, f(a) = b\n\\] （use \\(\\exists!\\)expresses only exist one）\nf: x–&gt;y is a bijection if and only if \\(\\exists\\)g:y—&gt;x, s.t. f(g(y))=\\(id_y\\) and g(f(x))=\\(id_x\\)"
  },
  {
    "objectID": "mth107.html#subsetsinclusions-restrictions",
    "href": "mth107.html#subsetsinclusions-restrictions",
    "title": "MTH107—NOTEs",
    "section": "",
    "text": "\\(A \\subseteq B\\)\n\n\n\n\\[\n\\emptyset \\to B\n\\]\n\n\n\nif A \\(\\subseteq\\) B, we have a map: \\[\n\\iota: A \\to B\n\\]\n\\[\n\\iota(a) = a\n\\], called the inclusion of A (into B)\n\n\n\nThat is:\nif A \\(\\subseteq\\) B and \\(f:B \\to C\\), we have a map for all a \\(\\in\\) A: \\[\nf|_A: A \\to C\n\\]:\n\\[\nf|_A(a) = f(a)\n\\] called the restriction of f to A\n\\[\nf|_A = f \\circ \\iota_A\n\\] because \\[\nf \\circ \\iota_A(a)=f(\\iota_A(a))=f(a)=f|_A(a)\n\\]\nthe reason to define it:\n\ndomains differ\n\nFor example, consider a map \\(g|_B: B \\to C\\), where the function takes each element \\(x\\) and maps it to \\(x + 2\\). Let the sets be as follows:\n\n\\(A = \\mathbb{N} \\subseteq B = \\mathbb{R}\\)\n\\(C = \\mathbb{R}\\) is the codomain of the function.\n\nThe map \\(g\\) is defined as: \\[ g: B \\to C, \\quad g(x) = x + 2 \\quad \\text{for all } x \\in B \\]\nNow, consider the restriction of \\(g\\) to \\(A\\), denoted \\(g|_A: A \\to C\\), where: \\[ g|_A: A \\to C, \\quad g|_A(x) = x + 2 \\quad \\text{for all } x \\in A \\]\nAlthough both \\(g: \\mathbb{R} \\to \\mathbb{R}\\) and \\(g|_A: \\mathbb{N} \\to \\mathbb{R}\\) follow the same rule \\(x \\mapsto x + 2\\), they cannot be considered the same map because their domains differ.\n(here, A \\(\\subseteq\\) B)\n\nfocus on the specific area within the whole area\n\n\n\n\nif a and b are sets we define \\(B^A={f:A---&gt;B (map)}\\) the set of all maps from A to B\n\\[\nB^A = \\{ f: A \\to B \\}\n\\] \\(B^\\emptyset = \\{ \\emptyset \\to B \\}\\) has only 1 element even if B=\\(\\emptyset\\)\n\nThe set \\(B^{\\emptyset}\\) contains only the zero function. proof: suppose f,g \\(\\in\\) \\(B^\\emptyset = \\{f: \\emptyset \\to B \\}\\), imagine f != g, we can derive \\(\\exists x \\in \\emptyset\\) s.t. f(x) != g(x), which is absurd, so f=g\n\nsuppose the only one element is sth.:\nsth. should follow the quality of the set, which is:\nsth. + sth. = sth.\n\\(\\lambda\\)sth. =sth.\nso sth. = 0\n\n\n(Def: let A be a.set, if A containsfinitely many elements, then the number of elements of A is called the cardinality of A, denoted by |A|(|A|\\(\\in Z_{\\geq0}\\))\n|| #\n|A|: number of elements in A(set))\nif A and B are finite sets #A=n #B=m, then \\(|B^A| = m^n\\) (ok)"
  },
  {
    "objectID": "mth107.html#relevant-to-dear-regression-analysis",
    "href": "mth107.html#relevant-to-dear-regression-analysis",
    "title": "MTH107—NOTEs",
    "section": "",
    "text": "MLR\n\n\nmatrix\n\n\nIn linear regression, we often work with matrix and vector representations. Given a matrix \\(X\\) (which represents the design matrix with each row corresponding to one observation and each column to a predictor), and a vector \\(Y\\) (representing the observed responses), the regression model can be written as:\n\\[\nY = X \\beta + \\epsilon\n\\]\nWhere: - \\(Y\\): The \\(n \\times 1\\) response vector, - \\(X\\): The \\(n \\times p\\) design matrix, - \\(\\beta\\): The \\(p \\times 1\\) vector of unknown coefficients, - \\(\\epsilon\\): The \\(n \\times 1\\) vector of errors or residuals.\nThe ordinary least squares (OLS) estimator for \\(\\beta\\), denoted \\(\\hat{\\beta}\\), is obtained by minimizing the residual sum of squares:\n\\[\n\\hat{\\beta} = (X^T X)^{-1} X^T Y\n\\]\n\n\n\nConsider two vectors \\(X_1\\) and \\(X_2\\). If \\(X_1^T X_2 = 0\\), we say the vectors are orthogonal, meaning they are uncorrelated in terms of inner product space. In regression, orthogonality implies no collinearity between predictors.\nOrthogonality plays an important role in simplifying matrix operations in regression. For example, if \\(X_1\\) is orthogonal to \\(X_2\\), the matrix \\(X^T X\\) will have off-diagonal elements equal to zero, simplifying the computation of the inverse.\n\n\n\nIf the matrix \\(X^T X\\) is invertible, the OLS estimator exists and is unique. One important property of the matrix \\(X^T X\\) is that it is symmetric and positive semi-definite. If \\(X\\) has full column rank (meaning that the columns of \\(X\\) are linearly independent), then \\(X^T X\\) is positive definite, and its inverse exists.\n\n\nIf \\(X^T X\\) is invertible, then:\n\\[\n(X^T X)^{-1} X^T X = I_p\n\\]\nWhere \\(I_p\\) is the identity matrix of size \\(p \\times p\\).\n\n\n\n\nThe projection matrix (or hat matrix) \\(P\\) is defined as:\n\\[\nP = X (X^T X)^{-1} X^T\n\\]\nThis matrix \\(P\\) projects the observed data vector \\(Y\\) onto the column space of \\(X\\), giving the fitted values \\(\\hat{Y}\\):\n\\[\n\\hat{Y} = P Y\n\\]\nThe residuals \\(\\hat{\\epsilon}\\), which are the differences between the observed and fitted values, are given by:\n\\[\n\\hat{\\epsilon} = Y - \\hat{Y} = (I_n - P) Y\n\\]\nWhere \\(I_n\\) is the \\(n \\times n\\) identity matrix. The projection matrix \\(P\\) has several key properties: - \\(P^2 = P\\) (idempotent), - \\(P^T = P\\) (symmetric).\n\n\n\nThe residual sum of squares (RSS) is given by:\n\\[\n\\text{RSS} = \\sum_{i=1}^{n} \\hat{\\epsilon}_i^2 = \\hat{\\epsilon}^T \\hat{\\epsilon} = (Y - X \\hat{\\beta})^T (Y - X \\hat{\\beta})\n\\]\nSubstituting \\(\\hat{\\beta} = (X^T X)^{-1} X^T Y\\), we get:\n\\[\n\\text{RSS} = Y^T (I_n - P) Y\n\\]\n\n\n\nThe variance-covariance matrix of the OLS estimator \\(\\hat{\\beta}\\) is:\n\\[\n\\text{Var}(\\hat{\\beta}) = \\sigma^2 (X^T X)^{-1}\n\\]\nWhere \\(\\sigma^2\\) is the variance of the error terms. This matrix provides information about the precision of the estimated coefficients.\n\n\n\n\nConsider a vector \\(y\\) in the vector space spanned by the columns of \\(X\\). The projection of \\(y\\) onto this space can be written as:\n\\[\n\\hat{y} = P y\n\\]\nIf \\(P\\) is the projection matrix, then the following properties hold: - \\(P^T = P\\) (symmetric), - \\(P^2 = P\\) (idempotent), - \\((I - P)\\) is also a projection matrix (projecting onto the orthogonal complement).\nThus, we can decompose any vector \\(Y\\) as:\n\\[\nY = \\hat{Y} + (Y - \\hat{Y}) = P Y + (I - P) Y\n\\]\nWhere \\(\\hat{Y}\\) is the projection onto the space spanned by \\(X\\), and \\((Y - \\hat{Y})\\) is the projection onto the orthogonal complement.\n\n\n\n\nA vector \\(\\perp\\) to a matrix \\(X\\) (i.e., orthogonal to the column space of the matrix \\(X\\)) implies that:\n\n\\[\nX^T v = 0\n\\]\nThis condition means that the vector \\(v\\) is orthogonal to every column of the matrix \\(X\\). In regression, this condition often arises when discussing residuals, which are orthogonal to the fitted values (i.e., the column space of \\(X\\)).\n\n\n\n\nIf \\(X^T v = 0\\), then \\(v \\perp X\\) (i.e., \\(v\\) is orthogonal to the column space of \\(X\\)).\nIf \\(X\\) has linearly independent columns, then \\(X^T X\\) is invertible.\nIf \\(X\\) does not have full column rank, then \\(X^T X\\) is not invertible. In this case, we cannot directly compute \\((X^T X)^{-1}\\).\n\n\n\n\nFor \\(X\\) to have full column rank, the number of columns \\(p\\) must be less than or equal to the number of observations \\(n\\):\n列空间的正交补空间只有零向量 he orthogonal complement of a column space has only zero vectors\nIf \\(X\\) has full column rank, then \\(X^T X\\) is invertible. This property is crucial for solving the normal equations in ordinary least squares (OLS) regression.\n\n\n\nGiven that \\(X^T X\\) is symmetric, the following property holds:\n\\[\n((X^T X)^{-1})^T = (X^T X)^{-1}\n\\]\nThis is a key result in linear regression, allowing us to solve for the OLS estimator of \\(\\beta\\):\n\\[\n\\hat{\\beta} = (X^T X)^{-1} X^T Y\n\\]\nThis property ensures that the normal equations have a unique solution when \\(X^T X\\) is invertible.\n\n\n\n\n\n正交性：矢量与矩阵的正交性在回归中经常用于描述残差与拟合值之间的关系。\n矩阵的性质：矩阵 \\(X^T X\\) 的可逆性取决于 \\(X\\) 的列满秩（线性无关性）。当 \\(X\\) 的列满秩时，\\(X^T X\\) 是可逆的，从而确保了线性回归模型的唯一解。\n矩阵运算：通过矩阵运算 \\((X^T X)^{-1}\\)，可以得到 OLS 回归系数的估计值 \\(\\hat{\\beta}\\)。"
  },
  {
    "objectID": "mth107.html#finite-space",
    "href": "mth107.html#finite-space",
    "title": "MTH107—NOTEs",
    "section": "finite space",
    "text": "finite space\nFor finite spaces ,only R^n and C^n.\n(For infinite spaces, there are many, e.g. a continuous set: [0,1] to …)"
  },
  {
    "objectID": "mth107.html#rn-notification",
    "href": "mth107.html#rn-notification",
    "title": "MTH107—NOTEs",
    "section": "R^n notification",
    "text": "R^n notification\n\\[\n\\mathbb{R}^n = \\{ (x_1, x_2, \\dots, x_n) \\mid x_i \\in \\mathbb{R} \\text{ for } i = 1, 2, \\dots, n \\}\n\\] real numbers\n\ndefine 2 oprations on the set R^n\naddition: \\[\n(x_1, x_2, \\dots, x_n) + (y_1, y_2, \\dots, y_n) = (x_1 + y_1, x_2 + y_2, \\dots, x_n + y_n)\n\\]\n\nLeft-hand side: \\((x_1, x_2, \\dots, x_n), (y_1, y_2, \\dots, y_n) \\in \\mathbb{R}^n\\)\nRight-hand side: The result of \\(x_i + y_i\\) is in \\(\\mathbb{R}\\).\n\nscalar multiplication: for lambda \\(\\in\\) R,\n\\[\n\\lambda \\cdot (x_1, x_2, \\dots, x_n) = (\\lambda x_1, \\lambda x_2, \\dots, \\lambda x_n)\n\\]\n\nLeft-hand side: \\(\\lambda \\in \\mathbb{R}, (x_1, x_2, \\dots, x_n) \\in \\mathbb{R}^n\\).\nRight-hand side: The result \\(\\lambda x_i \\in \\mathbb{R}\\), for each i.\n\nthese 2 oprations generalize the standard operations on R2 and R3\n\n\ngeometric realization\n矢量三角形–addition\n直线上–scalar multiplication\nmention: for n greater than or equal to 4 we cannot visualize vectors in the real world but e can still use them to solove real world problems\nif a and b are finite sets\n\n\nto simplify notations we sometimes use a single letter for vectors:\nx= \\(\\vec x\\) =(x_1,x_2,….)\nR^n as a vector space\nso we have(rn,+, mutiplication notation). the operations satisfies some useful properties that turn rn into a real vector space"
  },
  {
    "objectID": "mth107.html#relation-between-rn-and-.",
    "href": "mth107.html#relation-between-rn-and-.",
    "title": "MTH107—NOTEs",
    "section": "relation between rn and + .",
    "text": "relation between rn and + .\n\\((R^n,+,\\cdot)\\)\nit means that + and \\(\\cdot\\) satisfy the following axioms:\n\n\\(\\forall x,y \\in rn\\): x+y=y+x. commutativity\n\\(\\forall x,y,z \\in rn\\): (x+y)+z=x+(y+z). associativity\nx + 0 = 0 + x neutral element for addition\n\\(x + (-x) = (-x) + x = 0\\)\n\n——inverse for addition -x=y\n\n\\(1 \\cdot x = x\\) Identity Element for Scalar Multiplication\n\\((\\lambda \\mu) \\cdot x = \\lambda \\cdot (\\mu \\cdot x)\\) compatibilily of multiplication\n\\(\\lambda \\cdot (x + y) = \\lambda \\cdot x + \\lambda \\cdot y\\) Distributivity of Scalar Multiplication Over Vector Addition\n\\((\\lambda + \\mu) \\cdot x = \\lambda \\cdot x + \\mu \\cdot x\\) Distributivity of Scalar Addition\n\n\n?\nalso fn—f{1,..,n}\n5st ahead and the other 3（prove？eg tutorial1）. should we prove again or directly use them? tutorial 1 vs. 2 ’ s proof. ask again, sorry: since negative number set satisfies 2 oprations but not 8 axioms I want to ensure if a finite set satisfies the 2 operations it is not satisfy all 1-8 axioms instead of F^n so if the problem is a vector space V, we could directly suppose \\(\\exists u\\in F\\) and then do the scalar multiplication in it?\nis that because of the defination of F-vector space?(abstract vector space-defination)"
  },
  {
    "objectID": "mth107.html#cn-complex-vector-space",
    "href": "mth107.html#cn-complex-vector-space",
    "title": "MTH107—NOTEs",
    "section": "Cn complex Vector Space",
    "text": "Cn complex Vector Space\n\\(i^2 = -1\\)\nDefine \\(\\mathbb {C}^n\\) as the set of all ordered n-tuples of complex numbers: \\[\n\\mathbb{C}^n = \\{ (z_1, z_2, \\dots, z_n) \\mid z_i \\in \\mathbb{C}, \\, i = 1, 2, \\dots, n \\}\n\\]\n\nOperations on C^n\nWe define addition and scalar multiplication on \\(\\mathbb{C}^n\\) in the same way as we did on \\(\\mathbb{R}^n\\), but using complex numbers:\n\nAddition:\nFor two vectors \\((z_1, z_2, \\dots, z_n)\\) and \\((w_1, w_2, \\dots, w_n) \\in \\mathbb{C}^n\\):\n\\[\n(z_1, z_2, \\dots, z_n) + (w_1, w_2, \\dots, w_n) = (z_1 + w_1, z_2 + w_2, \\dots, z_n + w_n)\n\\]\n\n\nScalar Multiplication:\nFor a scalar \\(\\lambda \\in \\mathbb{C}\\) and a vector \\((z_1, z_2, \\dots, z_n) \\in \\mathbb{C}^n\\):\n\\[\n\\lambda \\cdot (z_1, z_2, \\dots, z_n) = (\\lambda z_1, \\lambda z_2, \\dots, \\lambda z_n)\n\\]\nThus, \\((\\mathbb{C}^n, +, \\cdot)\\) is a complex vector space because it satisfies the vector space axioms 1-8, where we replaced \\(\\mathbb{R}^n\\) with \\(\\mathbb{C}^n\\). Many of the results from MTH107 will hold regardless of whether we are using \\(\\mathbb{R}\\) or \\(\\mathbb{C}\\), so we will often use \\(\\mathbb{F}\\) to represent either \\(\\mathbb{R}\\) or \\(\\mathbb{C}\\).\nFor example, \\(\\mathbb{F}^n\\) is an \\(\\mathbb{F}\\)-vector space, where \\(\\mathbb{F}\\) could be either \\(\\mathbb{R}\\) or \\(\\mathbb{C}\\).\n\n\n\nGeneralization (Not on the Exam):\n\nFinite Field Example:\n\\(\\mathbb{F}_2 = \\{0, 1\\}\\): the finite field with two elements.\nMany of our results hold in a more general setting, where \\(\\mathbb{F}\\) is a field—a set in which we can perform addition, multiplication, subtraction, and division (except division by zero).\nExamples of fields include:\n\n\\(\\mathbb{R}\\): the real numbers\n\\(\\mathbb{C}\\): the complex numbers\n\\(\\mathbb{Q}\\): the rational numbers\n\\(\\mathbb{F}_2 = \\{0, 1\\}\\): the finite field with two elements"
  },
  {
    "objectID": "mth107.html#abstract-vector-space",
    "href": "mth107.html#abstract-vector-space",
    "title": "MTH107—NOTEs",
    "section": "Abstract Vector Space:",
    "text": "Abstract Vector Space:\nWe can generalize this idea by replacing \\(\\mathbb{F}^n\\) with some abstract space \\(V\\), define addition \\(+\\) and scalar multiplication \\(\\cdot\\), and check if they satisfy the eight vector space axioms.\n\nDefinitions:\nFor a set \\(V\\), addition on \\(V\\) is a map:\n\\[\nV \\times V \\to V\n\\]\nIt maps an element set to their addition. For example, if \\(V = \\mathbb{R}^2\\):\n\\[\n(v, w) \\mapsto v + w\n\\]\nExample: \\((1,2) + (3,4) = (4,6)\\), which is also in \\(V\\).\nA scalar multiplication is a map:\n\\[\nF \\times V \\to V\n\\]\nFor example, \\((\\lambda, v) \\mapsto \\lambda v\\).\n(remark:if V and W are sets, V\\(\\times\\) W = {(v,w)|v\\(\\in\\) V, w\\(\\in\\) W})\nAn \\(F\\)-vector space is a set \\(V\\) with an addition \\(+\\) and scalar multiplication \\(\\cdot\\) by elements of \\(F\\), such that \\((V, +, \\cdot)\\) satisfies the vector space axioms 1-8, where \\(\\mathbb{R}\\) is replaced by \\(F\\), and \\(\\mathbb{R}^n\\) is replaced by \\(V\\).\n\n\nRemarks and Examples:\n\nVectors: Vectors are elements of \\(V\\), denoted as \\(v \\in V\\).\nField \\(F\\): The choice of \\(F\\) matters! For example, we will see later that \\(\\mathbb{C}^n\\) is a complex vector space of dimension \\(n\\), but is also a real vector space of dimension \\(2n\\)."
  },
  {
    "objectID": "mth107.html#prove",
    "href": "mth107.html#prove",
    "title": "MTH107—NOTEs",
    "section": "？prove？",
    "text": "？prove？\nabove field F\n107’s learning need of C\n2n proof???\n\nExamples:\nFor any field \\(F\\),\n\nTrivial Vector Space: the set \\(V = \\{0\\}\\) is a trivial \\(F\\)-vector space with addition \\(0 + 0 = 0\\) and scalar multiplication \\(\\lambda \\cdot 0 = 0\\).\nFinite-Dimensional Vector Space: \\(F^n\\) is an \\(F\\)-vector space, and \\(F^0 = \\{0\\}\\).\nInfinite-Dimensional Vector Space: Let \\(F^\\infty\\) be the space of infinite sequences, where:\n\n\\[\nF^\\infty = \\{ (x_1, x_2, \\dots) \\mid x_i \\in F, \\, i = 1, 2, \\dots \\}\n\\]\nAddition and scalar multiplication are defined component-wise:\n\\[\n(x_1, x_2, \\dots) + (y_1, y_2, \\dots) = (x_1 + y_1, x_2 + y_2, \\dots)\n\\]\n\nFunction Space: Let \\(S\\) be a set, then:\n\n\\[\nF^S = \\{ f: S \\to F \\, \\text{(maps from S to F)} \\}\n\\]\nAddition and scalar multiplication are defined pointwise. For functions \\(f, g \\in F^S\\) and \\(\\lambda \\in F\\):\n\\[\n(f + g)(x) = f(x) + g(x) \\quad \\forall x \\in S\n\\]\n\\[\n(\\lambda \\cdot f)(x) = \\lambda \\cdot f(x) \\quad \\forall x \\in S\n\\]\n\\(F^S\\) is an F-vector space"
  },
  {
    "objectID": "mth107.html#section-1",
    "href": "mth107.html#section-1",
    "title": "MTH107—NOTEs",
    "section": "?",
    "text": "?\ndoes this thing have more explaination except for f：s to F\nis there any quick way to think this kind of question instead of proving 8 axioms one by one? such as geometry meaning like keep straight line and parallelogram in linear transformation\n\nproof of FS\n\\(F^S\\) is a vector space\nProof: we need to check the 8 axioms from the defination\n(core: use the element here to x and then see the equality of the 2 function on the each side of the equality using the quality of \\(\\mathbb F^n\\))\n\nf + g = g+f?\n\nthese 2 functions ((f+g)(x) and (g+f)(x)) are equal if and only if they have values agrees on every \\(s \\in S\\)\n\\[\n(f+g)(x)=f(x)+g(x)\n\\] which is \\(\\in F\\) so it is equal to g(x)+f(x)(addition axiom)=(g+f)(x)\n2)(f+g)+h = f+(g+h)\n[(f+g)+h](x)=(f+g)(x)+h(x)=[f(x)+g(x)]+h(x), which are \\(\\in F\\), so\n=f(x)+[g(x)+h(x)](axiom 3)=f(x)+(g+h)(x)=[f+(g+h)](x)\n\n\\(\\exists 0: 0+f=f\\) for any \\(f \\in F^S\\)\n\nyes, define the zero function \\(0_F:\\) to be the constant function \\(0_F\\), i.e. \\(0_F(x)=0_F\\)\n\nfor \\(f\\in F^S\\), can we find an inverse?\n\n-f is defined by (-f)(x)=-f(x)\ncheck: (f+(-f))(x)=f(x)+(-f(x))=\\(0_F\\)\nso f+(-f)=\\(0_{F^S}\\)\n\n1f=f \\(（1\\cdot f)(x)=1\\cdot f(x)(\\in F)=f(x)\\)\n(ab)f=a(bf)\n\npass\n7)a(f+g)=af+ag\na(f+g)(x)=a(f(x)+g(x))=af(x)+ag(x)=(af+ag)(x)\n8)(a+b)f=af+bf\n(a+b)f(x)=af(x)+bf(x)\n(af+bf)(x)=(af)(x)+(bf)(x)=af(x)+bf(x)\n\n\nSpecial Cases:\n\nEmpty Set: If \\(S = \\emptyset\\), then:\n\n\\[\nF^{\\emptyset} = \\{ 0 \\}\n\\] the proof has been proved above on “set of all maps from A to B(f)”\n\nFinite Set: If \\(S = \\{1, 2, \\dots, n\\}\\), then:\n\n\\[\nF^{\\{1, 2, \\dots, n\\}} = F^n\n\\]\n\nproof of special 2:\nLet \\(F^n\\) represent the n-dimensional vector space over a field \\(F\\), and \\(F^{\\{1, \\dots, n\\}}\\) represent the set of functions from the set \\(\\{1, \\dots, n\\}\\) to \\(F\\), i.e., it assigns a scalar from \\(F\\) to each index in \\(\\{1, \\dots, n\\}\\).\nWe will prove that there exists a linear map \\(T: F^n \\to F^{\\{1, \\dots, n\\}}\\) such that:\n\n\\(T\\) is a bijection (i.e., both injective and surjective).\n\\(T\\) preserves addition: \\[\nT(f + g) = T(f) + T(g)\n\\] for all \\(f, g \\in F^n\\).\n\\(T\\) preserves scalar multiplication: \\[\nT(a f) = a T(f)\n\\] for all \\(f \\in F^n\\) and \\(a \\in F\\).\n\nA map that satisfies these two conditions is called a linear map, and we will learn about it later in class. A linear map that is a bijection is called an isomorphism.\nDefine the Map \\(T\\)\nDefine the map \\(T: F^n \\to F^{\\{1, \\dots, n\\}}\\) as follows:\nFor each vector \\((a_1, a_2, \\dots, a_n) \\in F^n\\), define the corresponding function \\(T((a_1, a_2, \\dots, a_n)) = f \\in F^{\\{1, \\dots, n\\}}\\) by: \\[\nf(i) = a_i \\quad \\text{for each} \\, i = 1, 2, \\dots, n.\n\\] Thus, \\(T((a_1, a_2, \\dots, a_n)) = (f(1), f(2), \\dots, f(n)) = (a_1, a_2, \\dots, a_n)\\).\n\nInjectivity: \\(T((a_1, a_2, \\dots, a_n)) = T((b_1, b_2, \\dots, b_n))\\). This implies that for each \\(i\\), \\(a_i = b_i\\). Therefore, \\((a_1, a_2, \\dots, a_n) = (b_1, b_2, \\dots, b_n)\\), so \\(T\\) is injective. i.e. if \\(T(a_1,...a_n)=T(b_1,...,b_n)\\), then \\(\\forall i,\\) T(a)(i)=ai=T(b)(i)=bi,so\\(\\forall i,a_i=b_i\\),we need a=b\nSurjectivity: Given any function \\(f \\in F^{\\{1, \\dots, n\\}}\\), we can find a vector \\((a_1, a_2, \\dots, a_n) \\in F^n\\) such that \\(f(i) = a_i\\) for each \\(i = 1, 2, \\dots, n\\). Therefore, \\(T\\) is surjective.\n\ni.e., given \\(f\\in \\mathbb F^{\\{1,..n\\}}\\), then T(f(1),…f(n))=f with (f(1),…f(n))\\(\\in F^n\\)(T is {1,..n}–&gt;F) with (f(1),…f(n))\\(\\in F^n\\)\nSince \\(T\\) is both injective and surjective, it is a bijection.\nProve that \\(T\\) Preserves Addition\nLet \\((a_1, a_2, \\dots, a_n), (b_1, b_2, \\dots, b_n) \\in F^n\\). Then:\n\\[\nT((a_1, a_2, \\dots, a_n) + (b_1, b_2, \\dots, b_n)) = T((a_1 + b_1, a_2 + b_2, \\dots, a_n + b_n)).\n\\]\n\\[\nf(i) = a_i + b_i, \\quad i = 1, 2, \\dots, n.\n\\] (the definition of \\(T\\)) the other hand site: \\[\nT((a_1, a_2, \\dots, a_n)) + T((b_1, b_2, \\dots, b_n)) = (a_1, a_2, \\dots, a_n) + (b_1, b_2, \\dots, b_n),\n\\] which results f, also.\nProve that \\(T\\) Preserves Scalar Multiplication\nLet \\((a_1, a_2, \\dots, a_n) \\in F^n\\) and \\(c \\in F\\). Then: \\[\nT(c \\cdot (a_1, a_2, \\dots, a_n)) = T((c a_1, c a_2, \\dots, c a_n)).\n\\]\n\\[\nf(i) = c a_i, \\quad i = 1, 2, \\dots, n.\n\\] (the definition of \\(T\\))\nthe other hand site: \\[\nc \\cdot T((a_1, a_2, \\dots, a_n)) = c \\cdot (a_1, a_2, \\dots, a_n),\n\\] which also results in \\(f\\)\nSince T is an isomorphism (bijection + linear), then \\(T^{-1}\\) is automatically linear. That is we automatically have \\(T^{-1}(x+y)= T^{-1}(x)+ T^{-1}(y)\\), and the same for scalar multiplication. So they are the same in vector space, too.\nWe have shown that \\(T\\) is a bijection and preserves both addition and scalar multiplication. Therefore, \\(T\\) is a linear isomorphism, and \\(F^n\\) and \\(F^{\\{1, \\dots, n\\}}\\) are isomorphic as vector spaces.\n(Last remark: If \\(T\\) is an isomorphism (i.e., bijective and linear), then \\(T^{-1}\\) is automatically linear. That is, we automatically have \\(T^{-1}(x + y) = T^{-1}(x) + T^{-1}(y)\\), and the same holds for scalar multiplication. Therefore, there is no need to check these properties for \\(T^{-1}\\).)\n(a more detailed one proving bijetive: \\(F^{\\{1, 2, 3, \\dots, n\\}}\\) is Equivalent to \\(F^n\\)\nTo prove that \\(F^{\\{1, 2, 3, \\dots, n\\}}\\) is equivalent to \\(F^n\\), we show there is a bijection between the two sets, meaning each element in \\(F^{\\{1, 2, 3, \\dots, n\\}}\\) corresponds to a unique element in \\(F^n\\), and vice versa.\nBy definition, \\(F^{\\{1, 2, 3, \\dots, n\\}}\\) is the set of all functions from \\(\\{1, 2, 3, \\dots, n\\}\\) to \\(F\\). Each function \\(f\\) can be written as:\n\\[\nf = (f(1), f(2), \\dots, f(n)).\n\\]\n\\(F^n\\) is the set of ordered \\(n\\)-tuples \\((a_1, a_2, \\dots, a_n)\\), where each \\(a_i \\in F\\).\nMapping from \\(F^{\\{1, 2, 3, \\dots, n\\}}\\) to \\(F^n\\)—\nFor any function \\(f \\in F^{\\{1, 2, 3, \\dots, n\\}}\\), we define the corresponding tuple in \\(F^n\\) as:\n\\[\nT(f) = (f(1), f(2), \\dots, f(n)).\n\\]\nMapping from \\(F^n\\) to \\(F^{\\{1, 2, 3, \\dots, n\\}}\\)—-\nFor any tuple \\((a_1, a_2, \\dots, a_n) \\in F^n\\), define the corresponding function in \\(F^{\\{1, 2, 3, \\dots, n\\}}\\) as:\n\\[\nT^{-1}(a_1, a_2, \\dots, a_n)(i) = a_i, \\quad \\text{for each } i \\in \\{1, 2, \\dots, n\\}.\n\\]\nLet \\(f \\in F^{\\{1, 2, 3, \\dots, n\\}}\\)–\n\\[\nT(f) = (f(1), f(2), \\dots, f(n)).\n\\]\nthen, define\n\\[\nT^{-1}(f(1), f(2), \\dots, f(n))(i) = f(i), \\quad \\text{for each } i \\in \\{1, 2, \\dots, n\\}.\n\\]\nThus,\n\\[\nT^{-1}(T(f)) = f.\n\\]\nLet \\((a_1, a_2, \\dots, a_n) \\in F^n\\). Applying \\(T^{-1}\\), we get the function \\(f\\) such that \\(f(i) = a_i\\) for each \\(i\\). And then,\n\\[\nT(T^{-1}(a_1, a_2, \\dots, a_n)) = (a_1, a_2, \\dots, a_n).\n\\]\nThus,\n\\[\nT \\circ T^{-1} = \\text{id}_{F^n}.\n\\] This equation means that for any element \\((a_1, a_2, \\dots, a_n) \\in F^n\\), applying \\(T^{-1}\\) to obtain a function \\(f\\), and then applying \\(T\\) to \\(f\\), returns the original tuple:\n\\[\nT^{-1} \\circ T = \\text{id}_{F^{\\{1,2,3,...n\\}}}.\n\\]\nThis equation means that for any function \\(f \\in F^{\\{1, 2, 3, \\dots, n\\}}\\), applying \\(T\\) to obtain a tuple \\((f(1), f(2), \\dots, f(n))\\), and then applying \\(T^{-1}\\) to that tuple, returns the original function:\nSince \\(T\\) and \\(T^{-1}\\) are inverses of each other, we have established a bijection between \\(F^{\\{1, 2, 3, \\dots, n\\}}\\) and \\(F^n\\). Therefore, \\(F^{\\{1, 2, 3, \\dots, n\\}}\\) and \\(F^n\\) are equivalent as sets and vector spaces.)"
  },
  {
    "objectID": "mth107.html#linear-transformation-makes-us-know-everything",
    "href": "mth107.html#linear-transformation-makes-us-know-everything",
    "title": "MTH107—NOTEs",
    "section": "linear transformation makes us know everything",
    "text": "linear transformation makes us know everything\n二维映射到三维的linear transformation’s geometric meaning： if you know a transformation， then you know everything"
  },
  {
    "objectID": "mth107.html#general-properties-of-vector-space",
    "href": "mth107.html#general-properties-of-vector-space",
    "title": "MTH107—NOTEs",
    "section": "General properties of vector space",
    "text": "General properties of vector space\nLet V be a vector space over F\nWe will prove some properties of V using only the defination (axioms 1-8)\n\nProposition\n\nThe zero(additive identity) is unique. That is: \\(\\exists ! 0\\in V s.t. 0+V=V, \\forall v\\in V\\)\n\nproof: Suppose we have 2 zero elements: 0 and 0’\n0=0’+0=0+0’=0’\n\n\\(\\forall v\\in V\\) there exists a unique additive inverse\n\nSupppose w and w’ are 2 inverses for v, w=0+w=(v+w’)+w=v+(w’+w)=v+(w+w’)=(v+w)+w’=0+w’=w’\n\n\\(\\forall v\\in V\\), \\(O_F\\cdot V=O_V\\)\n\n\n\n?\n怎么想到的 why \\(0_F\\cdot V=0_V+w\\) F—&gt;V????\nwhy we could think of let w be the inverse of \\(0_F\\cdot V\\)? I always just could recite I mean remember the process instead of write it down smoothly\n(see 0_f as 0 is also okay)\nproof: \\(0_F\\)\\(\\cdot\\)V= \\((0_F+0_F)\\)\\(\\cdot\\)V=\\(0_Fv+0_Fv\\)\nlet w be the inverse of \\(0_F\\cdot v\\)(use proposition 2)\nthen \\(0_V\\)=\\(0_F\\cdot v+w\\)=\\((0_Fv+0_Fv)+w=0_Fv+(0_Fv+w)=0_Fv\\)\n\n\\(\\forall x\\in F: x\\cdot O_V=O_F\\)\n\nproof: \\(x\\cdot 0_V=x\\cdot (0_V+0_V)=x\\cdot 0_V+x\\cdot 0_V\\)\nso \\(0_V=x\\cdot 0_V\\)\n\n?\ndifference between o_Fv=0_v and xo_v=0_f(3 and 4 proposition)\n\n\n\nProperty\n\\(\\forall v\\in V,(-1)\\cdot V=-V\\)\nproof: V+(-1)V=(1+(-1))\\(\\cdot\\)V=0\\(\\cdot\\)V=0\nso (-1)V is an addictive inverse of V\nso we finish proof(by the addictive inverse)\n\nreminder of computing inverse of a matrix\nmethod1:\ndet(A)\n每一个位置的det构成的矩阵：B\ncofactor matrix:\\((-1)^{n+m}\\)\nC=B\\(\\times\\) cofactor matrix\n\\(A^{-1}=1/det(A)\\) times \\(C^T\\)\nmethod2: work for the tansformation of a matrix"
  },
  {
    "objectID": "mth107.html#motivation",
    "href": "mth107.html#motivation",
    "title": "MTH107—NOTEs",
    "section": "motivation",
    "text": "motivation\n\nif sets have subsets, vector spaces have subspaces.\n\n(Mathematicians study subobjects to understand the big objects better)"
  },
  {
    "objectID": "mth107.html#def",
    "href": "mth107.html#def",
    "title": "MTH107—NOTEs",
    "section": "Def",
    "text": "Def\nLet \\(V(V,+_V,\\cdot_V)\\)(what is the link with restrictions here?: we have \\(U\\subseteq V\\), i.e. U\\(\\times\\)U={(\\(x_1,x_2|x_1,x_2\\in U\\))}\\(\\subseteq V\\times V\\), now we have \\(+_V|_{U\\times U}\\):U\\(\\times U\\)–&gt;V, and scalar multiplication is similar to it. ) be a vector space, a subset U of V is a subspace if and only if \\(U(U,+_V,\\cdot_V)\\) is a vector space(for the link with restrictions: Here, for the condition of U being a vector space, we need\n\\(+_V|_{U\\times U}\\):U\\(\\times U\\)–&gt;U i.e. for \\(u_1,u_2\\in U, u_1+_vu_2 \\in U, \\lambda \\cdot_vu_1\\in U)\\)\n\\(\\cdot_v|_{F\\times U}\\): \\(F\\times U\\)–&gt;U\n\\(0_V\\in U\\)\n, which could replace 2 operations and 8 axioms and we will prove later)\nex: R=U\\(\\subseteq\\)V=C (a C-vector space) is not a subspace because scalar multiplication is not internal(i\\(\\cdot \\pi\\)is not in R—-not satisfying \\(\\cdot_v|_{F\\times U}\\): \\(F\\times U\\)–&gt;U)\n—-so we should explicit \\(\\mathbb F\\) when saying vector spaces"
  },
  {
    "objectID": "mth107.html#section-4",
    "href": "mth107.html#section-4",
    "title": "MTH107—NOTEs",
    "section": "?",
    "text": "?\nC r vector space though i including???\n(ex: \\(\\mathbb C\\)is a R-vector space and \\(\\mathbb R \\subseteq \\mathbb C\\) is a R subspace)"
  },
  {
    "objectID": "mth107.html#propsition",
    "href": "mth107.html#propsition",
    "title": "MTH107—NOTEs",
    "section": "Propsition",
    "text": "Propsition\n\\(U\\subseteq V\\)is a subspace if and only if :\na 0\nb +\nc \\(\\cdot\\)\n\nproof\nfor 1-8 axioms we only need to prove 4) because others are either included by the proposition or share the qualities of them because the elements in U are the elements in V.\n4): there exists only one inverse in U\ni.e. V’s inverse is in U\nlet \\(u\\in U\\), then \\(u\\in V\\) so \\(\\exists v=(-u)\\in V\\), we need to check is -u in U s.t. -u+u=\\(0_v\\):\n-u=(-1)u \\(\\in U\\)(scalar multiplication)"
  },
  {
    "objectID": "mth107.html#eg",
    "href": "mth107.html#eg",
    "title": "MTH107—NOTEs",
    "section": "eg",
    "text": "eg\n\n\\(\\lambda \\in \\mathbb F\\), U:={\\(x_1,x_2,x_3,x_4|x_3=5x_4+\\lambda\\)} is a subset if and only if \\(\\lambda =0\\)\n\nproof:\nside one: 0=(0,0,0,0) is in U… and others satisfy the proposition also.\nside two: if \\(\\lambda =0\\), let x and y \\(\\in U\\), so \\(x_3=5x_4\\),\\(y_3=5y_4\\), so \\(x_3+y_3=5(x_4+y_4)\\), so the addition is satisfied.\nfor c, also\n\n\\(R_\\{geq0}\\) is not a vector space–(-1,2)—&gt; (-1)2=-2\\(\\notin R_{\\geq0}\\)\n\\(C^0\\)([0,1]):={f:[0,1]–&gt;R, continuous} is a subspace \\(\\mathbb R^{[0,1]}\\)"
  },
  {
    "objectID": "mth107.html#proof-of-all-kinds-of-subspaces-of-r2",
    "href": "mth107.html#proof-of-all-kinds-of-subspaces-of-r2",
    "title": "MTH107—NOTEs",
    "section": "proof of all kinds of subspaces of R2",
    "text": "proof of all kinds of subspaces of R2"
  },
  {
    "objectID": "mth107.html#sum-of-subspaces",
    "href": "mth107.html#sum-of-subspaces",
    "title": "MTH107—NOTEs",
    "section": "sum of subspaces",
    "text": "sum of subspaces\n\nfor sets, if \\(A \\subseteq C\\) and \\(B\\subseteq C\\) are 2 subsets then A U B\\(\\subseteq\\)C is still a subset of C and it is the smallest subset of C containing both A and B.\n\nQ: what about subspaces of vector spaces?\nin general if U W are Z subspaces of V then U U W is not a subspace\nex:\n\nin fact U u W is a subspace if and only if \\(U \\subseteq W\\) or \\(W \\subseteq U\\)\n\nQ: How to produce the smallest subspace of V containing both U and W?\n\nDef: ley U_1,…U_n be subspaces of V then their SUM is \\(U_1+...+U_n=\\{ u_1+...+u_n|u_i\\in U_i ,\\forall i\\}\\). This is a subset of V containing all possible sums of elements of the U\n\nex\n\nThm: let U_1,…U_b be subspace of V then U_1+…+U_nis the smallest subspace of V containing each of the \\(U_i\\)\n\nProof: we need to prove the following 3 things:\n\nU:=\\(U_1+...+U_n\\) is a subspace\n\n0=0+..0(U_i are subspaces)\\(\\in U\\)\nif U=sum Ui and V=sum Vi \\(\\in U\\) then U+V=(sum ui)+(sum vi )=(u1+v1)+…\\(\\in U\\)\nif \\(\\lambda \\in F, U\\in U\\)(U is the sum of Ui(these subspaces))\n\nthen lambda(u sum)=(lambda u_1)+…\\(\\in U\\)\n\\(\\forall i: U_i\\subseteq U\\)\n\nlet v\\(\\in U_i\\) hten v=0+0+0(U_{i-1})+v(U_i)+0+0+0\\(\\in U\\), which means \\(U_i\\in U\\)\n\nif W is another subpace of V containing all the \\(U_i\\) then \\(U\\subseteq W\\)\n\nfor any \\(u\\in U\\), U(sum)\\(\\in W\\)(\\(U_i\\) \\(\\in W\\))(sum of elements of W), which means U\\(\\subseteq W\\)\n\n\nRemark:\n\n\\(U\\subseteq W\\) if and only if U+W=W\nproof:\n\nwe can do U+W only if U and W are subspaces of the same space\n\n\nComparison of subsets(A B)/subspaces(U W):\n\n\\(A\\cap B\\) is the biggest subset contained in both A and B\n\\(A \\cup B\\) is the smallest subspace containing both U and W\nA \\(\\sqcup\\) (disjoint union) B: whenever \\(A\\cap B=\\emptyset\\),then |A|+|B|=|\\(A\\cup B\\)|\nbut as the disjoint union for subspaces:\nmaybe ask that \\(U \\cap W\\) is as small as possible, that is L \\(U\\cap W=\\{0\\}\\)\n\nDef Let U1-Un be the subspaces of V we say that U1+Un is a DIRECT SUM if (shuangjiantou) \\(\\forall U\\in U sum\\) there exists a unique way to write U=Usum\nex:\n\nin this case we write U_1 \\(\\oplus\\)… \\(\\oplus\\) U_n\n(if \\(u\\in  U_1 +\\)… \\(+\\) \\(U_n\\), then there always exists \\(U_i\\in U_1 +\\)… \\(+\\) U_n\\(\\in U_n\\), such that U=U_1 \\(+\\)… \\(+\\) \\(U_n\\), the defination is about uniqueness of such elements.)\nex 1).U:={(x,x,y,y)|x,y\\(\\in F\\)}\\(\\subseteq F^4\\)\nW:={(x,x,x,y)|x,y\\(\\in F\\)}\\(\\subseteq F^4\\)\nthen U+W={(x,x,y,z)|x,y,z\\(\\in F\\)}=:A\nproof:\nside1:u+v\\(\\in U+W\\) easy —xxyz\nside2: let (x,x,y,z)\\(\\in A\\) we want to find v=(a,a,b,b), w=(c,c,c,d),s.t. u+w=(x,x,y,z)\nso we need to solve a+c=x, b+c=y,b+d=z,\nb is free, d=z-b,c=y-b,a=x-c=x-y+b\nfor ex for b=0:\nu=\nw=\nso u+w=\nso \\(A\\subseteq U+W\\)\nex 3) : \\(U_i=\\){(0,0,…x(i th coordinate),0,0,0(n th coordinate))|\\(x\\in F\\)}\\(\\subseteq F^n\\)\nthen \\(U_1\\oplus ...\\oplus U_n=F^n\\)\nex 4) : \\(U_1=\\){(x,y,z)|\\(x,y\\in F\\)}\n\\(U_2\\)={(0,0,z)|\\(z\\in F\\)}\n\\(U_3\\)={(0,y,y)|\\(y\\in F\\)}\nthen \\(U_1+U_2+U_3=F^3\\), but not direct sum\neg:\nbut \\(U_1\\odot U_2=F^3\\)\n\\(U_1\\odot U_3=F^3\\)\n\\(U_2\\odot U_3=\\{(0,y,z)|y,z\\in F^3\\}\\)\n```\n\nThm let U1,….Un be subspaces of V then [U1+…+Un is a direct sum] if and only if [if 0=u1+…+un, then u1=…=0]\n\nproof: one side is obvious: \\(0\\in U_1+...+U_n\\)\n   the other side: let v $\\in U_1+...+U_n$ with v= u+ =v+ be 2 decompsition \n\n\n   so o=u-v=(u1+)-(V1+)=(u1-v1)+(u2-v2)\n\n\n   SO 0 = U1-V1-U2-V2=... by assumption\n\n\n   so we can derive: u1=v1...\n\n\n   so the deconposition of v is unique\n\nintersection of subspaces:\n\nlemma: if U W are subspaces aof V then \\(U\\cap W\\) is the biggest subspace contained in both U and W\n\nproof :\nsubspace:\n\n0\n\n\nlambda\n\n\n\n-   already know $\\subseteq$\n\n-   biggest: let $Z\\subseteq V$ be a subspace, contained both in U and W, because $U\\cap W$ is the biggest subset contained both in U and W then $Z\\subseteq U\\cap W$(as subset)\n\nDef if V=U\\(\\oplus\\)W we say that W is COMPLEMENTARY SUBSPACE of U(inside V)\ngive a conunter example to:\nfor U1 U2, W subspaces of V, then\n\nif U1+w=U2+w, then U1=U2:\nif \\(U_1\\oplus W=U_2\\oplus W\\) hten U_1=U_2"
  },
  {
    "objectID": "mth107.html#linear-independence",
    "href": "mth107.html#linear-independence",
    "title": "MTH107—NOTEs",
    "section": "linear independence",
    "text": "linear independence\nfinite????\na list of vectors v,…vi\\(\\in V\\) is\n\nlinearly independent: if and only if the vector equation \\(\\lambda v_1+..=o\\) admits a unique solution: (0,0,)\n\nlinearly dependence: non-trivial solution.\ndet=0\nv,v,…,0,…\nremark\ninfinite\n\nv1,…vn is linearly independent if and only if span(v1)+span(v2)..+span(vn) is a direct sum.\n\nex: a list of 1 vector \\(v\\in V\\) is lin independent if and only if V!=0\nex: \\(u,v\\in V\\) is linearly independent if and only if [\\(u\\notin span(V)\\) and \\(v\\notin span(U)\\)]\n\nex: (0,0), (1,0) but v\\(\\notin span(u)=\\){0}\nif both u. and v !=0 then it is enough to check only one of a or b\n\nex: v1,… linearly dependent iff \\(\\exists i\\) s.t. $v_i$span(v1,….)\n\none side: \\(\\exists \\lambda\\)\nthe other side:\nsmalest span list:\n\none include\nthe other include:\n\nthis lemmma tells us the if a family is lin dependent then we can remove “redundan” vectors without changing the span\n\nTHM: suppose V=span(v1,..vm)=span(w1,..wn). If v1,..vm is linearly independent then \\(m\\leq n\\)\n\nproof:let us consider v1,w2,….,wn\n\nthis is a spannign family for v, \\(v=span(w1,..wn)\\subseteq span(v1,w1,...wn)\\subseteq v\\)\n\n-it is linearly dependent(because v1\\(\\in span(w1,...wn)....\\))\n\nv1 !=0 because v1,…vm is lin independent\n\n\n\nNow we apply the lemma to the family\n\nwhich implies that \\(\\exists j\\) s.t. wj can be replaced by v1\nindeed 0!= \\(\\notin span()\\)={0}\nsee photo in particular, \\(m \\leq n\\). ok\n\namong finite spanning lists, linearly independent are the smallest one\ncorollary: if v=span(v1,…vm)=span(w1,..wn) and (v1,..) and (w1,..) are both lin indep then m=n\nex: \\(\\mathbb F^n\\), any list of \\(m\\geq n+1\\) vectors is lin dependent because (1,0,..),(0,1,…),…(0,…,1) (n elements here) and any of \\(\\leq n-1\\) vecters cannot span \\(\\mathbb {F^n}\\)"
  },
  {
    "objectID": "mth107.html#begin",
    "href": "mth107.html#begin",
    "title": "MTH107—NOTEs",
    "section": "Begin",
    "text": "Begin\n\nDef Let V and W be 2 vector spaces over the same filed F. A maoo T V–&gt;W is a linear map(linear transformation) if and only if \\(\\forall v \\in V\\) T(u+v)=T(u)+T(v), \\(\\forall v \\in V, \\lambda\\in F\\) T(\\(\\lambda \\cdot v\\))= \\(\\lambda\\cdot T(v)\\)\nLemma Let T"
  },
  {
    "objectID": "mth107.html#problems",
    "href": "mth107.html#problems",
    "title": "MTH107—NOTEs",
    "section": "problems",
    "text": "problems\n\nsummarize1: give opposite example and draw pictures are okay.\n\neg.\neg. of Tutorial 4:\nf: \\(\\mathbb{R}_{\\geq0}\\)—&gt;\\(\\mathbb{R}\\)\nx–&gt;\\(\\sqrt {x}\\)\ng: \\(\\mathbb R\\)—&gt;\\(\\mathbb{R}_{\\geq0}\\)\nx–&gt;\\(x^2\\)\ng(f(x))=\\(x^2\\)=\\(id_{\\mathbb R\\geq0}\\) f(g(x))=|\\(x\\)|is not equal to \\(id_{\\mathbb R}\\) because f(g(x)) is not equal to x.\neg."
  },
  {
    "objectID": "mth107.html#understand-again",
    "href": "mth107.html#understand-again",
    "title": "MTH107—NOTEs",
    "section": "understand again",
    "text": "understand again\n see abstract vector space for a review"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Math is charismatic",
    "section": "",
    "text": "Many many and many…math is always expressing the secret in our magic nature…\n\n\nThe math teachers I have learned from are teaching math in an interesting and sophisticated way with different charismatic philosophy of themselves.\n\n\nI want to log the profound and inspiring things that I learned from my math teachers, including notes, philosophy and the like.\n\nAdvanced Linear Algebra and Linear Algebra\nAnalysis\nPDE intro\nmulti-variable calculus(geometric guys, sequence, …)\nmodeling knowledge\ninteresting problems"
  },
  {
    "objectID": "index.html#thanks",
    "href": "index.html#thanks",
    "title": "Math is charismatic",
    "section": "",
    "text": "The math teachers I have learned from are teaching math in an interesting and sophisticated way with different charismatic philosophy of themselves.\n\n\nI want to log the profound and inspiring things that I learned from my math teachers, including notes, philosophy and the like.\n\nAdvanced Linear Algebra and Linear Algebra\nAnalysis\nPDE intro\nmulti-variable calculus(geometric guys, sequence, …)\nmodeling knowledge\ninteresting problems"
  },
  {
    "objectID": "mth1113.html#it-is-not-stable-to-predict-the-data-outside-our-data-sample",
    "href": "mth1113.html#it-is-not-stable-to-predict-the-data-outside-our-data-sample",
    "title": "MTH113 Intro to probability and statistics+APH003–exploring world through data",
    "section": "it is not stable to predict the data outside our data sample’",
    "text": "it is not stable to predict the data outside our data sample’"
  },
  {
    "objectID": "mth1113.html#two-types-of-studies-observational-studies-and-experiments.",
    "href": "mth1113.html#two-types-of-studies-observational-studies-and-experiments.",
    "title": "MTH113 Intro to probability and statistics+APH003–exploring world through data",
    "section": "Two types of studies: Observational studies and Experiments.",
    "text": "Two types of studies: Observational studies and Experiments.\n\nObservational\nA study in which the investigator observes characteristics of a sample selected from one or more existing populations. The goal is to draw conclusions about the corresponding population or about differences between two or more populations.\nIn an observational study, it is impossible to draw clear cause-and-effect conclusions\n\n\nExperiments\nA study in which the investigator observes how a response variable behaves when one or more explanatory variables, also called factors, are manipulated.\nA well-designed experiment can result in data that provide evidence for a cause-and-effect relationship.\n\n\nExperimental conditions: Any particular combination of values for the explanatory variables, which are also called treatments.\n\n\n\ncomparison\n\nBoth observational studies and experiments can be used to compare groups, but in an experiment the researcher controls who is in which group, whereas this is not the case in an observational study.\nIn an observational study, it is impossible to draw clear cause-and\u0002effect conclusions\n\n\n\nconfounding vars\nA variable that is related to both how the experimental groups were formed and the response variable of interest.\n\nTwo methods for data collection: Sampling and Experimentation.\ndistinguish between selection bias, measurement or response bias, and non-response bias.\nselect a simple random sample from a given population.\ndistinguish between simple random sampling, stratified random sampling, cluster sampling, systematic sampling, and convenience sampling"
  },
  {
    "objectID": "mth1113.html#variable",
    "href": "mth1113.html#variable",
    "title": "MTH113 Intro to probability and statistics+APH003–exploring world through data",
    "section": "variable",
    "text": "variable\n\nresponse variable–y\nThe response variable is the focus of a question in a study or experiment.\n\n\nexplanotory variable–x\nAn explanatory variable is one that explains for changes in the response variable.\n\n\nexperiments and obeservational study\n\n\nbias\nselection bias：When the way the sample is selected systematically excludes some part of the population of interest.\nmeasurement or response bias\neg: survey question/scale(The scale or a machine used for measurements is not calibrated properly)\nNon-response Bias:When responses are not obtained from all individuals selected for inclusion in the sample.\nnon-response bias can distort results if those who respond differ in important ways from those who do not respond (e.g. laziness a confounding vari\u0002able).\n\n\nrandom sampling\ndef: A sample that is selected from a population in a way that ensures that every different possible sample of size n has the same chance of being selected.\nthe same chance to be selected\ncounter eg:\nConsider 100 students in a classroom, 60 females and 40 males. If we randomly sample 6 females, and 4 males, then each female has a 6/60 = 0.1 chance of being selected. Same for males, 4/40=0.1. However, not every group of 10 students is equally likely to be selected. This is not simple random sampling\nThe random selection process allows us to be confident that the sample adequately reflects the population, even when the sample consists of only a small fraction of the population.\neg.Voting Sample Size in a country\n\n\nstratified and cluster\n\nstratified random sampling:In stratified random sampling, separate simple random samples are independently selected from each subgroup. Each subgroup is called a strata.\n\nIn general, it is much easier to produce relatively accurate es\u0002timates of characteristics of a homogeneous group than of a heterogeneous group.\nstratified: according to certain characteristic\neg.Even with a small sample, it is possible to obtain an accurate estimate of the average grade point average (GPA) of students graduating with high honours from a university (Similar high grades, homogenous, thus only sample a few students). On the other hand, producing a reasonably accurate estimate of the average GPA of all seniors at the university, a much more diverse group of GPAs, is a more difficult task. Not only does this ensure that students at each GPA level are represented, it also allows for a more accurate estimate of the overall average GPA.\n\ncluster reflect general characteristic about the whole entire population\n\ncluster: randomly groups\nCluster sampling involves dividing the population of interest into non-overlapping subgroups, called clusters. Clusters are then selected at random, and then all individuals in the selected clusters are included in the sample.\n\n\nsystematic sampling\nA value k is specified (e.g. k = 50 or k = 200). Then one of the first k individuals is selected at random, after which every k-th individual in the sequence is included in the sample. A sample selected in this way is called a 1 in k systematic sample.\nIn the case of large samples, it can ensure that the sample is evenly distributed in the population."
  },
  {
    "objectID": "mth1113.html#definition-random-variable-r.v.",
    "href": "mth1113.html#definition-random-variable-r.v.",
    "title": "MTH113 Intro to probability and statistics+APH003–exploring world through data",
    "section": "Definition: Random Variable (R.V.)",
    "text": "Definition: Random Variable (R.V.)\nA numerical variable whose value depends on the outcome of a chance experiment. A random variable associates a numerical value with each outcome of a chance experiment.(Think of it as a rule that translates each result of a chance event into a number.)\nA real-valued random variable X is a function\nX : S → \\(\\mathbb R\\), where S is the sample space of a chance experiment.\nDiscrete random variable: A random variable is discrete if its set of possible value is a collection of isolated points along the number line.(counting)\nContinuous random variable: A random variable is continuous if its set of possible values includes an entire interval on the number line.(measurement)\n\neg\nExamples: Coin Tossing (Discrete Random Variable) If we flip a coin 5 times, let X be the number of heads we get. Possible values of X {0,1,2,3,4,5} (where 0 means no heads, and 5 means all heads). Here, X turns each outcome of multiple coin tosses into a count of heads. Departure Time (Continuous Random Variable) Imagine tracking when people leave a subway station between 10 PM and 11 PM. Let Y represent the time (in hours) someone leaves, so Y can be any number from 10 to 11. Here, Y assigns each departure time to a point in the range [10,11].\n\n\nexplaination\nIn short:\nRandom variables convert random events into numbers. Discrete random variables take specific values (like counting heads). Continuous random variables take any value in a range (like time).\n\nMultiple variables"
  },
  {
    "objectID": "mth1113.html#probability-mass-function-and-cumulative-distribution-function-for-discrete-random-variables",
    "href": "mth1113.html#probability-mass-function-and-cumulative-distribution-function-for-discrete-random-variables",
    "title": "MTH113 Intro to probability and statistics+APH003–exploring world through data",
    "section": "Probability Mass Function and Cumulative Distribution Function for Discrete Random Variables",
    "text": "Probability Mass Function and Cumulative Distribution Function for Discrete Random Variables\nProbability Mass Function (PMF): \\(p_x (x) := P(X = x) ,\\forall x\\)\nCumulative Distribution Function (CDF): \\(F_x (x) := P(X \\leq x) ,\\forall x\\)\n\n# 定义每个事件的概率和对应的 X 值\noutcomes &lt;- c(\"GGGG\", \"EGGG\", \"GEGG\", \"GGEG\", \"GGGE\", \n              \"EEGG\", \"EGEG\", \"EGGE\", \"GEEG\", \"GEGE\", \n              \"GGEE\", \"GEEE\", \"EEEG\", \"EEGE\", \"EEEE\")\nprobabilities &lt;- c(0.1296, 0.0864, 0.0864, 0.0864, 0.0864, \n                   0.0576, 0.0576, 0.0576, 0.0576, 0.0576, \n                   0.0384, 0.0384, 0.0384, 0.0384, 0.0256)\nX_values &lt;- c(0, 1, 1, 1, 1, \n              2, 2, 2, 2, 2,\n              3, 3, 3, 3, 4)\n\n# 计算每个 X 值的 PMF 通过分组和求和\npmf &lt;- tapply(probabilities, X_values, sum)\n\n# 定义可能的 X 值\nX_values_unique &lt;- sort(unique(X_values))\n\n# 计算 CDF\ncdf &lt;- cumsum(pmf)\n\n# 确保 CDF 在 x &gt; 4 时为 1\ncdf &lt;- c(cdf, 1)\n\n# 更新 X 值以包括 x &gt; 4 的情况\nX_values_unique &lt;- c(X_values_unique, \"&gt;4\")\n\n# 创建数据框显示 PMF 和 CDF\ntable &lt;- data.frame(\n  X = X_values_unique,\n  `PMF P(X=x)` = c(pmf, 1-0.1296-0.3456-0.2880-0.1536-0.0256),  # PMF 没有对应的 x &gt; 4 值，填 NA\n  `CDF F(X&lt;=x)` = cdf\n)\n\n# 打印表格\nprint(table)\n\n   X PMF.P.X.x. CDF.F.X..x.\n0  0     0.1296      0.1296\n1  1     0.3456      0.4752\n2  2     0.2880      0.7632\n3  3     0.1536      0.9168\n4  4     0.0256      0.9424\n  &gt;4     0.0576      1.0000\n\n\n\nNote that the domain of a cdf is (−∞, ∞)\n\n\\(\\mathrm{pmf} \\Longrightarrow \\mathrm{cdf}\\) \\[\nF_x(x)=\\sum_{y \\leq x} p_x(y)\n\\] cdf \\(\\Longrightarrow\\) pmf Suppose \\(X\\) takes ordered values \\(x_1, x_2, x_3, \\cdots\\), then \\[\n\\begin{aligned}\np_X\\left(x_i\\right) & =P\\left(X=x_i\\right)=P\\left(x_{i-1}&lt;X \\leq x_i\\right) \\\\\n& =P\\left(X \\leq x_i\\right)-P\\left(X \\leq x_{i-1}\\right) \\\\\n& =F\\left(x_i\\right)-F\\left(x_{i-1}\\right)\n\\end{aligned}\n\\]\n\nremark: The probability of a discrete distribution varies depending on the inclusion and exclusion of the boundary values."
  },
  {
    "objectID": "mth1113.html#expectation-and-variance-for-discrete-random-variables",
    "href": "mth1113.html#expectation-and-variance-for-discrete-random-variables",
    "title": "MTH113 Intro to probability and statistics+APH003–exploring world through data",
    "section": "Expectation and Variance for Discrete Random Variables",
    "text": "Expectation and Variance for Discrete Random Variables\n\\[\n\\frac{0 \\cdot f_0+1 \\cdot f_1+2 \\cdot f_2+\\cdots+n \\cdot f_n}{N}=\\frac{1}{N} \\sum_{i=0}^n i \\cdot f_i\n\\]\nNote that in \\(\\frac{1}{N} \\sum_{i=0}^n i \\cdot f_i\\), \\[\n\\lim _{N \\rightarrow \\infty} \\frac{f_i}{N}=P(X=i)\n\\]\nSo the average number will be \\[\n\\sum_{i=0}^n i \\cdot P(X=i)\n\\]\n\nDefinition: Expectation Given a discrete random variable \\(X\\), the expectation of \\(X\\) is \\[\nE[X]=\\sum_x x \\cdot p_X(x)\n\\]\nProperties of Expectation\nIf \\(c\\) is a constant, then \\(E[c]=c\\).\nIf \\(X \\geq 0\\) then \\(E[X] \\geq 0\\).\nIf \\(a \\leq X \\leq b\\) then \\(a \\leq E[X] \\leq b\\).\nProof of 3: First show \\(E[X] \\geq a\\), then show \\(E[X] \\leq b\\), \\[\n\\begin{aligned}\nE[X] & =\\sum_x x p_X(x) \\geq \\sum_x a p_X(x), \\\\\n& =a \\sum_x p_x(x)=a .\n\\end{aligned}\n\\]\n\nSimilarly, \\(E[X] \\leq b\\).\n\nSuppose \\(X\\) is a discrete random variable and \\(Y=g(X)\\), then \\[\n\\begin{aligned}\nE[Y] & =\\sum_y y p_Y(y)=\\sum_y y P(Y=y) \\\\\n& =\\sum_y y \\sum_{\\{x: g(x)=y\\}} P(X=x) \\\\\n& =\\sum_y \\sum_{\\{x: g(x)=y\\}} y P(X=x) \\\\\n& =\\sum_y \\sum_{\\{x: g(x)=y\\}} g(x) P(X=x) \\\\\n& =\\sum_x g(x) P(X=x)\n\\end{aligned}\n\\]\nFirst moment of \\(X\\) (mean): \\[\nE[X]=\\sum_x x p_X(x) .\n\\]\nSecond moment of \\(X\\) : \\[\nE\\left[X^2\\right]=\\sum_x x^2 p_x(x) .\n\\]\nIn general, \\(E[g(X)] \\neq g(E[X])\\). For example, let \\(g(x)=x^2\\), and consider \\(X\\) such that \\[\np_X(x)= \\begin{cases}0.5, & \\text { for } x=-1 \\\\ 0.5, & \\text { for } x=1\\end{cases}\n\\]\n\nThen clearly \\(E\\left[X^2\\right]=1 \\neq 0=(E[X])^2\\).\n\nThere are exceptions (e.g. when g is linear)!\nLinearity of Expectation\n\nE[aX + b] = aE[X] + b\nproof:\nSuppose \\(g(x)=a x+b\\). Then \\[\n\\begin{aligned}\nE[g(X)] & =\\sum_x g(x) p_X(x), \\\\\n& =\\sum_x(a x+b) p_x(x), \\\\\n& =\\sum_x a x p_x(x)+\\sum_x b p_x(x), \\\\\n& =a \\sum_x x p_x(x)+b \\sum_x p_x(x), \\\\\n& =a E[X]+b=g(E[X]),\n\\end{aligned}\n\\] this implies \\[\nE[a X+b]=a E[X]+b\n\\]\n\nRemark: Apart from this case, always assume \\(E[g(X)] \\neq g(E[X])\\)."
  }
]